\section{سوال پنجم - تئوری}
چگونه می‌توان آموزش خصمانه را در مجموعه داده‌های نامتوازن پیاده‌سازی کرد و چه چالش‌هایی در این مسیر وجود دارد؟





\begin{qsolve}
آموزش خصمانه بر روی مجموعه‌داده‌های نامتوازن چالش‌های خاصی دارد و نیازمند توجه دقیق به منظور اطمینان از مقاومت در برابر حملات خصمانه و عملکرد خوب در کلاس‌های اقلیتی است. در ادامه به نحوه پیاده‌سازی آموزش خصمانه بر روی مجموعه‌داده‌های نامتوازن و چالش‌های خاص آن می‌پردازیم


\begin{enumerate}
	\item \textbf{پیاده‌سازی آموزش خصمانه بر روی مجموعه‌داده‌های نامتوازن}
	\begin{enumerate}
		\item ایجاد مثال‌های خصمانه:
		\begin{itemize}
			\item 
از تکنیک‌هایی مانند \lr{FGSM} (روش گرادیان سریع)، \lr{PGD} (گرادیان پروژه‌شده) یا سایر الگوریتم‌های حمله خصمانه برای ایجاد مثال‌های خصمانه استفاده کنید.

			\item 
می‌بایست اطمینان حاصل شود که مثال‌های خصمانه برای هر دو کلاس اکثریت و اقلیت ایجاد می‌شوند تا مدل به سمت کلاس اکثریت منحرف نشود.
		\end{itemize}
		
		
		\item آموزش خصمانه متوازن:
		\begin{itemize}
			\item 
آموزش خصمانه با وزن‌دهی به کلاس‌ها: به مثال‌های خصمانه از کلاس‌های اقلیت وزن بیشتری اختصاص دهید تا تاثیر بیشتری بر فرآیند یادگیری مدل داشته باشند.


			\item 
افزایش تعداد نمونه‌ها: برای ایجاد تعادل در مجموعه‌داده‌های آموزش خصمانه، تعداد بیشتری از مثال‌های خصمانه برای کلاس‌های اقلیت ایجاد کنید. این کار می‌تواند با ایجاد چندین مثال خصمانه از هر نمونه کلاس اقلیت انجام شود.

	
			\item 
کاهش تعداد نمونه‌ها: تعداد مثال‌های خصمانه برای کلاس اکثریت را کاهش دهید تا مجموعه‌داده‌های آموزشی متوازن شوند. این کار باید با احتیاط انجام شود تا از دست دادن اطلاعات مهم کلاس اکثریت جلوگیری شود.
		\end{itemize}
		
		
		\item روش‌های ترکیبی:
		\begin{itemize}
			\item 
ترکیب تکنیک‌های افزایش و کاهش تعداد نمونه‌ها برای حفظ یک مجموعه‌داده آموزشی خصمانه متوازن.


			\item 
استفاده از تکنیک‌های افزایش داده‌ها برای ایجاد نمونه‌های مصنوعی برای کلاس‌های اقلیت و اطمینان از تنوع و جلوگیری از بیش‌برازش.
		\end{itemize}
		
		
		
		\item آموزش خصمانه تطبیقی:
		\begin{itemize}
			\item 
تنظیم پویا قدرت حمله خصمانه بر اساس توزیع کلاس‌ها. به عنوان مثال، استفاده از اختلالات قوی‌تر برای کلاس‌های اکثریت و اختلالات ملایم‌تر برای کلاس‌های اقلیت برای حفظ تعادل.
		\end{itemize}
		
		
		
		
		\item توابع زیان متوازن برای کلاس‌ها:
		\begin{itemize}
			\item 
پیاده‌سازی توابع زیانی که عدم توازن کلاس‌ها را در نظر می‌گیرند، مانند زیان کانونی که زیان اختصاص داده شده به مثال‌های به‌خوبی طبقه‌بندی شده را کاهش می‌دهد و تمرکز بیشتری به مثال‌های سخت و کلاس‌های اقلیت می‌دهد.


			\item 
استفاده از تکنیک‌های یادگیری حساس به هزینه که برای طبقه‌بندی نادرست نمونه‌های کلاس اقلیت جریمه‌های بالاتری در نظر می‌گیرند.
		\end{itemize}
	\end{enumerate}
\end{enumerate}
	
\end{qsolve}





\begin{qsolve}
	\begin{enumerate}
		\item [2.]\textbf{چالش‌ها در آموزش خصمانه بر روی مجموعه‌داده‌های نامتوازن}
		\begin{enumerate}
			\item حفظ تعادل:
			\begin{itemize}
				\item
ایجاد یک مجموعه‌داده متوازن از مثال‌های خصمانه چالش‌برانگیز است زیرا کلاس اکثریت معمولاً داده‌های بیشتری دارد، که منجر به عدم توازن در مثال‌های خصمانه نیز می‌شود.

				\item 
افزایش نمونه‌های کلاس‌های اقلیت می‌تواند منجر به بیش‌برازش شود، در حالی که کاهش نمونه‌های کلاس‌های اکثریت می‌تواند به از دست رفتن اطلاعات مهم منجر شود.
			\end{itemize}
			
			\item اختلالات موثر:
			\begin{itemize}
				\item 
ایجاد مثال‌های خصمانه موثر برای کلاس‌های اقلیت سخت‌تر است به دلیل محدودیت تعداد نمونه‌ها، که می‌تواند بر مقاومت و تعمیم مدل تاثیر بگذارد.

				\item 
اطمینان از اینکه مثال‌های خصمانه برای کلاس‌های اقلیت بی‌اهمیت یا خیلی آسان برای مدل نباشند.
			\end{itemize}
			
			
			\item پیچیدگی محاسباتی:
			\begin{itemize}
				\item 
آموزش خصمانه محاسباتی سنگین است و متوازن کردن آن برای مجموعه‌داده‌های نامتوازن پیچیدگی را افزایش می‌دهد. ایجاد مثال‌های خصمانه متعدد برای کلاس‌های اقلیت و حفظ تنوع به بار محاسباتی می‌افزاید.
			\end{itemize}
			
			
			\item معیارهای ارزیابی:
			\begin{itemize}
				\item 
ارزیابی عملکرد مدل‌های آموزش‌دیده خصمانه بر روی مجموعه‌داده‌های نامتوازن پیچیده است. معیارهایی مانند دقت کافی نیستند؛ معیارهایی مانند دقت، فراخوانی، امتیاز \lr{F1} و \lr{AUC-ROC} اطلاعات بیشتری برای مجموعه‌داده‌های نامتوازن فراهم می‌کنند.


				\item 
اطمینان از عملکرد خوب مدل بر روی مثال‌های تمیز و خصمانه برای کلاس‌های اقلیت بدون کاهش عملکرد کلی.
			\end{itemize}
			
			
			\item توازن بین مقاومت و دقت:
			\begin{itemize}
				\item 
آموزش خصمانه اغلب منجر به توازن بین مقاومت و دقت می‌شود. اطمینان از اینکه این توازن به طور نامتناسبی کلاس‌های اقلیت را تحت تاثیر قرار نمی‌دهد بسیار مهم است.


				\item 
حفظ مقاومت مدل در برابر حملات خصمانه در حالی که دقت بالایی برای هر دو کلاس اکثریت و اقلیت دارد.
			\end{itemize}
		\end{enumerate}
		
		
		
		\item [3.]\textbf{استراتژی‌های کاهش چالش‌ها}
		\begin{enumerate}
			\item استفاده از روش‌های گروهی:
آموزش چندین مدل با تکنیک‌های مختلف متوازن‌سازی و ترکیب پیش‌بینی‌های آنها برای دستیابی به عملکرد بهتر در هر دو کلاس اکثریت و اقلیت.
			
			
			\item تکنیک‌های منظم‌سازی:
استفاده از روش‌های منظم‌سازی مانند دراپ‌آوت، کاهش وزن و توقف زودهنگام برای جلوگیری از بیش‌برازش، به ویژه هنگام افزایش نمونه‌های کلاس‌های اقلیت.
			
			
			\item افزایش داده‌های پیشرفته:
استفاده از تکنیک‌های افزایش داده‌های پیچیده که نمونه‌های مصنوعی با کیفیت بالا برای کلاس‌های اقلیت تولید می‌کنند و نمایندگی آنها را در مجموعه‌داده‌ها افزایش می‌دهند.
			
			
			\item آموزش خصمانه پویا:
پیاده‌سازی استراتژی‌های آموزشی پویا که تمرکز بین کلاس‌های اکثریت و اقلیت را بر اساس پیشرفت آموزش و معیارهای عملکرد مشاهده شده تنظیم می‌کنند.
		\end{enumerate}
	\end{enumerate}
\end{qsolve}
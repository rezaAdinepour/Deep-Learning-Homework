\section{سوال ششم - تئوری}
در این سوال می‌خواهیم یک حمله خصمانه با روش‌های \lr{FGSM} طراحی کنیم و سپس مدل از پیش آموزش داده شده \lr{ResNet18} را با آموزش خصمانه مقاوم سازیم. به این منظور مراحل زیر را دنبال کنید:


\begin{enumerate}
	\item 
مدل از پیش آموزش دیده \lr{ResNet18} را برای مجموعه داده \lr{CIFAR10} آموزش دهید. نمودار خطا آموزش و آزمون را رسم کنید.

	\item 
روش \lr{FGSM} را پیاده‌سازی کنید و 5 تصویر را به صورت تصادفی انتخاب کنید و به مدل حمله کنید. سپس برای این تصاویر، تصویر اصلی، تصویر آشفته شده\footnote{\lr{‫‪Perturbed‬‬}}، پرچسب اصلی و پرچسب پیش‌بینی شده بر روی تصویر آشفته شده را نمایش دهید.


	\item 
حال با گنجاندن نمونه‌های خصمانه در فرآیند آموزش، مدل \lr{ResNet18} را دوباره آموزش دهید (آموزش خصمانه). این فرآیند به مدل کمک می‌کند تا در برابر حملات خصمانه مقاوم‌تر شود. نحوه آموزش را کامل شرح دهید. نمودارهای زیر را در کنار هم رسم و تفسیر کنید.

	\begin{itemize}
		\item 
		\lr{train-natural}: خطای آموزش برروی مدل طبیعی
		
		\item 
		\lr{train-adversary}: خطای آموزش برروی مدل خصمانه
		
		\item 
		\lr{test-natural}: خطای آموزش برروی مدل طبیعی (مجموعه داده آزمون بدون تغییر)
		
		\item 
		\lr{test-adversary}: خطای آموزش برروی مدل خصمانه (مجموعه داده آزمون بدون تغییر)
	\end{itemize}
	
	
	\item 
تا اینجا ما توانستیم تا با حملات خصمانه تصویری که تفاوت بسیار کمی با دیتای اصلی دارد، مدل را به اشتباه بیندازیم. حال می‌خواهیم به صورت هدفمند اینکار را انجام دهیم؛ یعنی مدل باید به اشتباه کلاس مورد نظر ما را پیش‌بینی کند\footnote{\lr{Target Attack}}. با روش \lr{FGSM} حمله هدفمند را پیاده‌سازی و نحوه انجام آن را بطور کامل شرح دهید. حال با ایجاد نمونه‌های خصمانه جدید از مجموعه داده آزمون و همچنین داده‌های آزمون بدون تغییر، صحت هر دو مدل را (مدل طبیعی و مدل آموزش دیده به صورت خصمانه) را ارزیابی کنید. نتایج را تفسیر کنید. در مورد اثربخشی آموزش خصمانه در بهبود استحکام مدل در برابر حملات خصمانه بحث کنید.
\end{enumerate}





\begin{qsolve}

\end{qsolve}
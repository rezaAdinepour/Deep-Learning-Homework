\section{سوال دوم - تئوری}
چگونه آموزش خصمانه\footnote{\lr{Adversarial Training}} می‌تواند بر تعمیم پذیری مدل به داده‌های دیده نشده تاثیر بگذارد؟ آیا همیشه بهبود در مقاومت شدن در برابر حملات، بهبود صحت بر روی داده‌های دیده نشده را تضمین می‌کند؟ نشان دهید.


\begin{qsolve}
	\begin{enumerate}
		\item \textbf{توازن بین مقاومت و دقت: }
		\begin{itemize}
			\item بهبود مقاومت:\\
آموزش خصمانه به طور عمده مقاومت مدل در برابر حملات خصمانه را بهبود می‌بخشد. با معرفی نمونه‌های خصمانه به مدل در طول آموزش، مدل یاد می‌گیرد که حتی در مواجهه با ورودی‌های دست‌کاری شده نیز پیش‌بینی‌های دقیقی انجام دهد.


			\item دقت در داده‌های تمیز:\\
در حالی که آموزش خصمانه می‌تواند مقاومت را به طور قابل توجهی افزایش دهد، اغلب با کاهش دقت در داده‌های تمیز (غیر دست‌کاری شده) همراه است. این به این دلیل است که مدل ممکن است بیش از حد بر روی نمونه‌های خصمانه تمرکز کند و توانایی تعمیم‌دهی به نمونه‌های عادی و غیر خصمانه کاهش یابد.
		\end{itemize}
		
		
		
		\item \textbf{تعمیم‌پذیری به داده‌های دیده‌نشده: }
		\begin{itemize}
			\item توانایی تعمیم‌دهی:\\
در برخی موارد، مقاومتی که توسط آموزش خصمانه ایجاد می‌شود، می‌تواند به مدل کمک کند تا به داده‌های دیده‌نشده خاصی بهتر تعمیم دهد، به ویژه اگر داده‌های دیده‌نشده شامل نویز یا تغییرات مشابه نمونه‌های خصمانه باشد. با این حال، اگر داده‌های دیده‌نشده تمیز باشند، ممکن است مدل نسبت به مدلی که بدون نمونه‌های خصمانه آموزش دیده، عملکرد ضعیف‌تری داشته باشد.
			
			\item تنوع توزیع داده‌ها:\\
قابلیت تعمیم‌دهی مدل همچنین به این بستگی دارد که نمونه‌های خصمانه چقدر نماینده تغییرات احتمالی در داده‌های دیده‌نشده هستند. اگر نمونه‌های خصمانه به خوبی طراحی شده باشند و طیف وسیعی از تغییرات ممکن را پوشش دهند، می‌توانند به مدل کمک کنند تا بهتر تعمیم دهد. در مقابل، اگر نمونه‌های خصمانه بیش از حد خاص باشند، ممکن است مدل با توزیع داده‌های جدیدی که به خوبی نمایندگی نشده‌اند، مشکل داشته باشد.
		\end{itemize}
	\end{enumerate}
	
بهبود مقاومت در برابر حملات خصمانه در مقابل دقت بر روی داده‌های دیده‌نشده همیشه تضمین نمی‌شود، بهبود مقاومت در برابر حملات خصمانه همیشه دقت بهتر بر روی داده‌های دیده‌نشده را تضمین نمی‌کند. فرآیند آموزش خصمانه می‌تواند گاهی منجر به \lr{overfitting} به نمونه‌های خصمانه شود که ممکن است به خوبی به نمونه‌های جدید و دیده‌نشده تعمیم ندهد.

دستیابی به تعادل بین مقاومت و دقت نیاز به توجه دقیق به داده‌های آموزشی و انواع نمونه‌های خصمانه مورد استفاده دارد. تکنیک‌های \lr{regularization}، \lr{data augmentation} و سایر روش‌ها می‌توانند به کاهش تأثیر منفی بر دقت کمک کنند در حالی که مقاومت را نیز بهبود می‌بخشند.

\end{qsolve}
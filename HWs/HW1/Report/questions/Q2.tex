\section{سوال دوم - عملی}
مجموعه داده ضمیمه شده را بارگزاری کرده و آن را نمایش دهید. تفکیک مجموعه داده را با نسبت ۱:۲:۷ به‌ترتیب برای آموزش، آزمون و اعتبارسنجی درنظر بگیرید.

\textbf{تمامی کدهای سوالات عملی پیوست شده است. همچنین می‌توانید کد‌ها را از گیتهاب بنده به لینک زیر مشاهده و بررسی کنید: }

\begin{latin}
	\texttt{\href{https://github.com/rezaAdinepour/Deep-Learning-Homework}{github.com/rezaAdinepour/Deep-Learning-Homework}} 
\end{latin}

\textbf{همچنین به دلیل آنکه تمامی کد ها در فایل های \texttt{notebook} به طور کامل توضیح داده شده است، در این گزارش به دلیل جلوگیری از طولانی شدن آن، از آوردن کد پرهیز کرده ایم.}


\begin{qsolve}
	
	پس از load کردن دیتاست و تقسیم کردن آن به ۳ دسته آموزش، تست و اعتبار سنجی، آن را رسم کردیم. خروجی به صورت زیر است:
	
	\begin{center}
		\includegraphics*[width=1\linewidth]{pics/img7.png}
		\captionof{figure}{دیتاست مسئله}
		\label{دیتاست مسئله}
	\end{center}
	
	همانطور که مشاهده می‌شود، داده ها جداپذیر حطی نیستند پس نمی‌توان به صورت معمولی آن را با شبکه پرسپترون حل نمود. در این سوال تلاش خواهیم کرد با روش‌های معرفی شده در سوال ۱، به صورت عملی با شبکه پرسپترون، یک مسئله غیر خطی را حل نماییم.
\end{qsolve}



\begin{enumerate}
	\item با یک نورون پرسپترونی و صرفا بر اساس ویژگی های ورودی، وزن‌های نورون خود را با آموزش بدست آورید و دسته‌بندی را انجام دهید. و معیار های صحت\footnote{\lr{Accuracy}} و امتیاز F1 را به ازای هر دسته گزارش نمایید. همچنین در نهایت وزن‌های معماری‌تان را به همراه طرحواره آن گزارش کنید.
	
	
	
	\begin{qsolve}
		شبکه پرسپترون تک لایه با استفاده از کتابخانه \texttt{PyTorch} تعریف شده است. از تابع Sigmoid به عنوان تابع فعال‌ساز استفاده شده است. در این شبکه از تابع بهینه‌ساز \lr{stochastic gradient descent} استفاده شده است و برای محاسبه خطا، از \lr{mean squared error} به عنوان تابع هزینه استفاده شده است.
		
		پس از ۵۰۰ ایپاک آموزش شبکه، خروجی شبکه به صورت زیر شده است:
		\begin{latin}
			\texttt{Epoch 500/500, Loss: 0.3373, Accuracy: 0.5263, F1 Score: 0.5115}\\
			\texttt{---------------------------------------------------------------}\\
			\texttt{Validation Loss: 0.3900, Validation Accuracy: 0.5173, Validation F1 Score: 0.4689
			}\\
			\texttt{---------------------------------------------------------------}
		\end{latin}
		
		همچنین نمودار‌های دقت و خطا بر حسب تعداد \lr{Epoch} به صورت زیر شده است:
		
		\begin{center}
			\includegraphics*[width=1\linewidth]{pics/img8.png}
			\captionof{figure}{نمودار های خطا و دقت}
			\label{نمودار های خطا و دقت}
		\end{center}
		
		همانطور که از نمودار ها و خروجی شبکه مشاهده می‌شود، نشان از نوسان بالا در شبکه را دارد که کاملا طبیعیست چرا که داده ها جداپذیر خطی نیستند و شبکه هرچه تلاش می‌کند تا دو کلاس را از هم تفکیک کند نمی‌تواند و دچار نوسان می‌شود. مقدار \lr{Loss} از ۰٫۳ پایین تر نمی‌آید همچنین مشاهده می‌شود دقت روی مجموعه داده اعتبارسنجی بعد از ایپاک ۳۰۰ به شدت افت شده است.
		
		
		ماتریس پراکندگی\footnote{\lr{Confusion matrix}} برای مجموعه داده‌های آموزش، تست و اعتبارسنجی به صورت زیر شده است:
		
		\begin{center}
			\includegraphics*[width=1\linewidth]{pics/img9.png}
			\captionof{figure}{ماتریس پراکندگی}
			\label{ماتریس پراکندگی ۱}
		\end{center}
	\end{qsolve}
	
	
	
	
	
	
	
	\begin{qsolve}
		از خروجی ماتریس‌های پراکندگی نیز مشاهده می‌شود که تعداد نمونه های که اشتباه شناسایی شده اند (نمونه های روی قطر فرعی) زیاد هستند که نشان از عدم آموزش شبکه دارد.
		
		پس از فاز آموزش شبکه، نوبت به تست شبکه آموزش داده شده به وسیله مجموعه داده‌های تست می‌رسد. خروجی شبکه بر روی داده های تست به صورت زیر شده است:
		
		\begin{latin}
			\texttt{Test loss: 0.3493, Test Accuracy: 0.5289, Test F1 Score: 0.5289}
		\end{latin}
		
		وزن‌های نهایی شبکه پس از آموزش به صورت زیر به‌دست آمده است:
		\begin{latin}
			\texttt{Final weights: tensor([[ 0.1273, -0.1831]], device='cuda:0')}
		\end{latin}
	\end{qsolve}
	
	
	
	
	
	
	\item به ورودی قسمت قبل، توان بالای ورودی ها تا توان سوم را افزوده و نتیجه حاصل را ضمن گزارش تحلیل نموده و توجیه کنید.
	
	\begin{qsolve}
		در این قسمت، ابتدا توان دوم و سوم ورودی را محاسبه می‌کنیم و هر دو آن را به شبکه می‌دهیم. بر اساس آنچه که در سوال اول توضیح دادیم، ممکن است با به توان رساندن ویژگی های ورودی داده هایی که جداپذیر خطی نیستند، جداپذیر خطی شوند. در این مثال داده هارا پس از به توان رساندن رسم کردیم:
		
		\begin{center}
			\includegraphics*[width=1\linewidth]{pics/img10.png}
			\captionof{figure}{ویژگی های به توان رسانده شده}
			\label{ویژگی های به توان رسانده شده}
		\end{center}
		
		همانطور که از «شکل \ref{ویژگی های به توان رسانده شده}» مشاهده می‌شود، توان دوم داده‌های ورودی جداپذیر خطی شده است و امکان حل آن با یک نرون پرسپترون وجود دارد اما توان سوم داده‌های ورودی همچنان جداناپذیر خطی است. توان چهارم نیز تست شد، آن هم جداناپذیر خطی بود اما به دلیل آنکه در صورت سوال خواسته نشده است. گزارش آن آورده نشده است.
		
		انتظار داریم اگر به ورودی شبکه، توان دوم داده‌های دیتاست را بدهیم، شبکه بتواند مسئله را حل نماید و مقدار Loss آن مینیمم و Accuracy آن ماکزیمم شود. این‌بار داده‌های جدید را با همان شبکه قبلی مجدد Train می‌کنیم و خروجی‌های آن را گزارش می‌دهیم.
		
		پس از آموزش شبکه با ویژگی های جدید، خروجی شبکه به صورت زیر به‌دست آمده است:
		
		\begin{latin}
			\texttt{Epoch 500/500, Loss: 0.0760, Accuracy: 0.9051, F1 Score: 0.8139}\\
		\end{latin}
	\end{qsolve}
	
	
	\begin{qsolve}
		\begin{latin}
			\texttt{---------------------------------------------------------------}\\
			\texttt{Validation Loss: 0.1162, Validation Accuracy: 0.7977, Validation F1 Score: 0.7822}\\
			\texttt{---------------------------------------------------------------}\\
		\end{latin}
		
				مشاهده می‌شود که مقدار Loos گزارش شده بر روی داده های آموزش بسیار کوچکتر از حالت قبل است و تقریبا نزدیک به صفر. همچنین Accuracy شبکه نیز نسبت به حال قبل مقدار ۴۰ درصد افزایش یافته است. مقادیر گزارش شده بر روی داده‌های اعتبارسنجی نیز نسبت به حال قبل بهبود یافته اند.
		
		نمودار Loss و Accuracy خروجی شبکه به صورت زیر گزارش می‌شود:
		\begin{center}
			\includegraphics*[width=1\linewidth]{pics/img11.png}
			\captionof{figure}{نمودار‌های خطا و دقت}
			\label{نمودار‌های خطا و دقت ۲}
		\end{center}
		
		نوسانات کمتری نسبت به قسمت قبل در نمودار Accuracy مشاهده می‌شود و دیگر دقت برای مجموعه داده های اعتبارسنجی افت نکرده است. همچنین مقدار خطا نیز با شیب بیشتری نسبت به حالت قبل کاهش پیدا کرده است.
		
		خروجی ماتریس پراکندگی شبکه نیز به صورت زیر است:
		\begin{center}
			\includegraphics*[width=1\linewidth]{pics/img12.png}
			\captionof{figure}{ماتریس پراکندگی}
			\label{ماتریس پراکندگی ۲}
		\end{center}
		
		مشاهده می‌شود که نمونه های درست طبقه‌بندی شده (نمونه های روی قطر اصلی) نسبت به حال قبل بیشتر است و همچنین نمونه های اشتباه نیز به مراتب کمتر از حالت قبل است.
		
	\end{qsolve}
	
	
		
	\begin{qsolve}
		خروجی شبکه بر روی مجموعه داده‌های Test به صورت زیر شده است:
		
		\begin{latin}
			\texttt{Test loss: 0.0965, Test Accuracy: 0.8300, Test F1 Score: 0.6127}\\
		\end{latin}
		
		خروجی شبکه بر روی داده های تست نیز بهبود زیادی نسبت به حالت قبل داشته است.
		
		همچنین وزن‌های نهایی شبکه به صورت زیر گزارش می‌شود:
		\begin{latin}
			\texttt{Final weights: tensor([[-0.0438, -0.0453]], device='cuda:0')}\\
		\end{latin}
		
		
		مجددا تمام مراحل را برای توان سوم داده‌های ورودی تکرار می‌کنیم. مطابق با «شکل \ref{ویژگی های به توان رسانده شده}» انتظار داریم خروجی شبکه پس از آموزش تقریبا همانند توان اول داده ها باشد، چرا که در هر دو حالت داده‌ها جداناپذیر خطی هستند. خروجی شبکه آموزش دیده بر روی توان سوم داده‌های ورودی به صورت زیر گزارش می‌شود:
		
		\begin{latin}
			\texttt{Epoch 500/500, Loss: 0.4831, Accuracy: 0.4759, F1 Score: 0.3548}\\
			\texttt{---------------------------------------------------------------}\\
			\texttt{Validation Loss: 0.4572, Validation Accuracy: 0.5167, Validation F1 Score: 0.3793}
		\end{latin}
		
		با توجه به نتایج بدست آمده، پیش‌بینی ما درست است. چرا که مقدار خطا نسبت به حالت دوم، مجددا افزایش یافته و دقت نیز کاهش یافته است. نمودار های خروجی نیز مطابق با شکل زیر گزارش می‌شود:
		
		\begin{center}
			\includegraphics*[width=1\linewidth]{pics/img13.png}
			\captionof{figure}{نمودار‌های خطا و دقت}
			\label{نمودار‌های خطا و دقت ۳}
		\end{center}
		
		از نمودار ها نیز می‌توان نتیجه گرفت که شبکه به درستی آموزش ندیده است چرا که در ۵۰۰ تکرار مقدار خطا خیلی نرم و با شیب کمی کاهش یافته است همچنین مقدار دقت نیز در طول فرایند آموزش تقریبا ثابت بوده است.
		
		خروجی ماتریس‌های پراکندگی نیز به صورت زیر گزارش می‌شود:	
	\end{qsolve}
	
	
	\begin{qsolve}
		\begin{center}
			\includegraphics*[width=1\linewidth]{pics/img14.png}
			\captionof{figure}{ماتریس پراکندگی}
			\label{ماتریس پراکندگی ۳}
		\end{center}
		
		در این حالت نیز مجددا نمونه های روی قطر غیر اصلی ماتریس افزایش یافته است که نشان از عدم طبقه‌بندی درست مسئله دارد.
		
		خروجی شبکه بر روی مجموعه دادگان تست به صورت زیر گزارش می‌شود:
		\begin{latin}
			\texttt{Test loss: 0.4470, Test Accuracy: 0.5133, Test F1 Score: 0.3883}\\
		\end{latin}
		
		شبکه بر روی داده‌های تست نیز خروجی مطلوبی ندارد و مقدارLoss و Accuracy آن نسبت به حالت قبل افت کرده است.
		
		وزن‌های نهایی شبکه به صورت زیر گزارش می‌شود:
		
		\begin{latin}
			\texttt{Final weights: tensor([[0.0587, 0.1524]], device='cuda:0')}\\
		\end{latin}
	\end{qsolve}
	
	
	
	
	\item حال حاصل ضرب ورودی‌های قسمت قبل برای مثال \lr{($x_1x_2, x_1x_2^2,x_1^3x_2$)} را به ورودی پرسپترون افزوده و مجددا نتیجه حاصل را ضمن گزارش تحلیل نموده و توجیه کنید. به جهت ریاضیاتی و هندسی، این جمله‌ها بیانگر افزودن چه ویژگی‌هایی هستند؟
	
	\begin{qsolve}
		برای بدست ویژگی های جدید این قسمت، از کلاس \texttt{PolynomialFeatures} در کتابخانه \texttt{sklearn} استفاده کرده ایم. این کلاس ویژگی های ورودی را می‌گیرد و بر اساس درجه ای که برای آن مشخص می‌کنیم، تمام ترکیبات چند جمله ای تا آن درجه را تولید می‌کند. برای مثال اگر ماتریس ویژگی‌های ما به صورت زیر باشد:
		
		$$
		X=\begin{bmatrix} 
			0 & 1 \\ 
			2 & 3 \\ 
			4 & 5 
		\end{bmatrix}
		$$
		
		با فراخوانی کلاس \texttt{PolynomialFeatures} و فیت کردن داده ها با تابغ \texttt{fit\_transform} به صورت زیر برای ساختن ویژگی‌های چند جمله ای حداکثر تا توان ۲:
		
		\begin{latin}
			\texttt{poly = PolynomialFeatures(degree=2, include\_bias=True)}\\
			\texttt{X\_poly = poly.fit\_transform(X)}
		\end{latin}
		
		خروجی (ماتریس ویژگی‌های جدید) به صورت زیر خواهد بود:
	\end{qsolve}
	
	
	
	
	
	\begin{qsolve}
		$$
		X_{new}=\begin{bmatrix} 
			1 & 0 & 1 & 0 & 0 & 1\\
			1 & 2 & 3 & 4 & 6 & 9\\ 
			1 & 4 & 5 & 16 & 20 & 25\\ 
		\end{bmatrix}
		$$
		
		در ويزگی جدید، علاوه بر دو مقدار قبل، در درایه اول هر سطر، بایاس با مقدار ۱ اضاف می‌شود، همچنین در درایه های ۳ تا ۶ در هر سطر، به ترتیب ویژگی های $a^2,ab,b^2$ حساب شده است.
		
		تعریف رسمی این کلاس در داکیومنت \texttt{sklearn} به صورت زیر است:
		
		\begin{latin}
			Generate a new feature matrix consisting of all polynomial combinations
			of the feaxtures with degree less than or equal to the specified degree.
			For example, if an input sample is two dimensional and of the form
			[a, b], the degree-2 polynomial features are $[1, a, b, a^2, ab, b^2]$.
		\end{latin}
		
		
		
	\end{qsolve}
	
	
	
	
	
	
	
	
	
	
\end{enumerate}







































%سیستم زیر را در نظر بگیرید:
%
%\begin{figure}[h]
%	\centering
%	\includegraphics*[width=0.6\linewidth]{pics/q2_1.png}
%\end{figure}
%
%سیگنال ورودی $x_c(t)$ دارای تبدیل فوریە ی زیر است.
%
%\begin{figure}[h]
%	\centering
%	\includegraphics*[width=0.3\linewidth]{pics/q2_2.png}
%\end{figure}
%
%که در آن :
%
%\[
%	\Omega_0=2\pi 1000rad/s
%\]
%
%سیستم گسسته زمان یک فیلتر پایین گذر ایده آل با پاسخ فرکانسی زیر است.
%
%\[
%	H(e^{j\omega})=\begin{cases}
%		1 & |\omega|<\omega_c \\
%		0 & \text{otherwise}
%	\end{cases}
%\]
%
%الف) کمینه نرخ نمونه برداری که در آن aⅼiasing رخ نمیدهد چقدر است؟
%
%\begin{qsolve}[]
%    کمینه نرخ نمونه برداری از حد نایکوییست بدست میاید بدین صورت که:
%    \[
%        \omega_s=\frac{2\pi}{T_s}\geq\omega_{nq}=2\omega_{max}=2\Omega_0\Rightarrow
%        T_s\leq\frac{\pi}{\Omega_0}=\frac{1}{2000}s=0.5ms
%    \]
%\end{qsolve}
%
%ب) اگر $\omega_c=\pi/2$ کمینه نرخ نمونه برداری به طوری که $y_t(t)=x_c(t)$؟
%
%
%\begin{qsolve}[]
%    اگر شرط نایکوییست ارضا شود، خواهیم داشت که:
%    \[
%        X(e^{j\Omega})=X_p(j\omega)\when_{\Omega=\omega T}    
%    \]
%    حال میخواهیم بعد از گسسته شدن، فیلتر اثری روی سیگنال نگذارد، یعنی کل محتوای فرکانسی زیر 
%    $\omega_c$ باشد. آنگاه:
%    \[
%      \Omega_{max}=\omega_{max}T=\Omega_0T\leq\omega_c=\frac{\pi}{2}\Rightarrow T\leq\frac{\pi}{2\Omega_0}
%      =\frac{1}{4000}s=0.25ms  
%    \]
%    که این شرط محدودیت بیشتری از شرط نایکوییست اعمال میکند.
%\end{qsolve}

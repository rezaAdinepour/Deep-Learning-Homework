{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poems analysis\n",
    "----\n",
    "\n",
    "In this notebook we will use Minisom to cluster poems from three different authors.\n",
    "\n",
    "Requirements:\n",
    "- Glove vectors, https://nlp.stanford.edu/projects/glove/ glove.6B.50d.txt\n",
    "- Beautiful soup\n",
    "- An internet connection as the poems will be downlaoded from www.poemhunter.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "def scrape_poem(poem_url):\n",
    "    poem_page = urlopen(poem_url).read()\n",
    "    soup = BeautifulSoup(poem_page)\n",
    "    poem = ''\n",
    "    poem_string = soup.find_all(\"div\", \n",
    "                                {\"class\": \"KonaBody\" })[0].find_all('p')[0]\n",
    "    poem_string = str(poem_string)[3:-4].replace('<br/>', ' ')\n",
    "    return poem_string\n",
    "\n",
    "def scrape_poems_index(poems_index_url):\n",
    "    poems_index = urlopen(poems_index_url).read()    \n",
    "    soup = BeautifulSoup(poems_index)\n",
    "    pages = soup.find_all(\"div\", {\"class\": \"pgbluev1\"})\n",
    "    if len(pages) == 0:\n",
    "        return get_all_links(soup)\n",
    "    \n",
    "    pages = pages[0].find_all('a')\n",
    "    \n",
    "    result = {}\n",
    "    cnt = 0\n",
    "    for page in pages:\n",
    "        page_link = 'https://www.poemhunter.com/'+page['href']\n",
    "        page_soup = BeautifulSoup(urlopen(page_link))\n",
    "        result.update(get_all_links(page_soup))\n",
    "    return result\n",
    "\n",
    "def get_all_links(page_soup):\n",
    "    result = {}    \n",
    "    for link in page_soup.find_all(\"p\", {\"class\": \"cl333\"}):\n",
    "        link = link.find_all('a')[0]\n",
    "        result[link['title']] = 'https://www.poemhunter.com/'+link['href']\n",
    "    return result\n",
    "\n",
    "def get_poems(poems_index, max_poems=None):\n",
    "    poems = {}\n",
    "    for i, (title, poem_url) in enumerate(poems_index.items()):\n",
    "        print('fetching', title, '...')\n",
    "        try:\n",
    "            poems[title] = scrape_poem(poem_url)\n",
    "            print('OK')\n",
    "        except:\n",
    "            print('impossible to fetch')\n",
    "        if i == max_poems-1:\n",
    "            return poems\n",
    "    return poems\n",
    "\n",
    "poems_index_neruda = scrape_poems_index('https://www.poemhunter.com/pablo-neruda/poems/')\n",
    "poems_index_bukowski = scrape_poems_index('https://www.poemhunter.com/charles-bukowski/poems/')\n",
    "poems_index_poe = scrape_poems_index('https://www.poemhunter.com/edgar-allan-poe/poems/')\n",
    "\n",
    "poems_neruda = get_poems(poems_index_neruda, max_poems=60)\n",
    "poems_bukowski = get_poems(poems_index_bukowski, max_poems=60)\n",
    "poems_poe = get_poems(poems_index_poe, max_poems=60)\n",
    "\n",
    "\n",
    "all_poems = [poems_neruda, poems_bukowski, poems_poe]\n",
    "titles = np.concatenate([list(title_list.keys()) for title_list in all_poems])\n",
    "y = np.concatenate([[i]*len(p) for i, p in enumerate(all_poems)])\n",
    "all_poems = np.concatenate([list(p.values()) for p in all_poems])\n",
    "\n",
    "\n",
    "from string import punctuation\n",
    "import stop_words\n",
    "stopwords = stop_words.get_stop_words('english')\n",
    "\n",
    "def tokenize_poem(poem):\n",
    "    poem = poem.lower().replace('\\n', ' ')\n",
    "    for sign in punctuation:\n",
    "        poem = poem.replace(sign, '')\n",
    "    tokens = poem.split()\n",
    "    tokens = [t for t in tokens if t not in stopwords and t != '']\n",
    "    return tokens\n",
    "\n",
    "tokenized_poems = [tokenize_poem(poem) for poem in all_poems]\n",
    "\n",
    "\n",
    "def gimme_glove():\n",
    "    with open('glove.6B/glove.6B.50d.txt', encoding='utf-8') as glove_raw:\n",
    "        for line in glove_raw.readlines():\n",
    "            splitted = line.split(' ')\n",
    "            yield splitted[0], np.array(splitted[1:], dtype=np.float)\n",
    "            \n",
    "glove = {w: x for w, x in gimme_glove()}\n",
    "\n",
    "def closest_word(in_vector, top_n=1):\n",
    "    vectors = glove.values()\n",
    "    idx = np.argsort([np.linalg.norm(vec-in_vector) for vec in vectors])\n",
    "    return [glove.keys()[i] for i in idx[:top_n]]\n",
    "\n",
    "\n",
    "def poem_to_vec(tokens):\n",
    "    words = [w for w in np.unique(tokens) if w in glove]\n",
    "    return np.array([glove[w] for w in words])\n",
    "\n",
    "W = [poem_to_vec(tokenized).mean(axis=0) for tokenized in tokenized_poems]\n",
    "W = np.array(W)\n",
    "\n",
    "from minisom import MiniSom\n",
    "map_dim = 16\n",
    "som = MiniSom(map_dim, map_dim, 50, sigma=1.0, random_seed=1)\n",
    "#som.random_weights_init(W)\n",
    "som.train_batch(W, num_iteration=len(W)*500, verbose=True)\n",
    "\n",
    "author_to_color = {0: 'chocolate', # neruda\n",
    "                   1: 'steelblue', # bukowski\n",
    "                   2: 'dimgray'}   # poe \n",
    "color = [author_to_color[yy] for yy in y]\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=author_to_color[0], edgecolor='white',label='neruda'),\n",
    "                   Patch(facecolor=author_to_color[1], edgecolor='white',label='bukowski'),\n",
    "                   Patch(facecolor=author_to_color[2], edgecolor='white',label='poe'),]\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "texts = []\n",
    "for i, (t, c, vec) in enumerate(zip(titles, color, W)):\n",
    "    winnin_position = som.winner(vec)\n",
    "    texts.append(plt.text(winnin_position[0], \n",
    "                 winnin_position[1]+np.random.rand()*.9, \n",
    "                 t[:-5],\n",
    "                 color=c))\n",
    "\n",
    "plt.legend(handles=legend_elements, loc='upper left')\n",
    "plt.xticks(range(map_dim))\n",
    "plt.yticks(range(map_dim))\n",
    "plt.grid()\n",
    "plt.xlim([0, map_dim])\n",
    "plt.ylim([0, map_dim])\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /usr/lib/python3/dist-packages (3.8.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: twython in /home/reza/.local/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: requests>=2.1.0 in /home/reza/.local/lib/python3.11/site-packages (from twython) (2.31.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.0 in /home/reza/.local/lib/python3.11/site-packages (from twython) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/reza/.local/lib/python3.11/site-packages (from requests>=2.1.0->twython) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/reza/.local/lib/python3.11/site-packages (from requests>=2.1.0->twython) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.1.0->twython) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.1.0->twython) (2022.9.24)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.4.0->twython) (3.2.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in /home/reza/.local/lib/python3.11/site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in /usr/lib/python3/dist-packages (from textblob) (3.8.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wordcloud in /home/reza/.local/lib/python3.11/site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /usr/lib/python3/dist-packages (from wordcloud) (1.24.2)\n",
      "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from wordcloud) (10.0.0)\n",
      "Requirement already satisfied: matplotlib in /home/reza/.local/lib/python3.11/site-packages (from wordcloud) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/reza/.local/lib/python3.11/site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/reza/.local/lib/python3.11/site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/reza/.local/lib/python3.11/site-packages (from matplotlib->wordcloud) (4.45.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/reza/.local/lib/python3.11/site-packages (from matplotlib->wordcloud) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from matplotlib->wordcloud) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->wordcloud) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib->wordcloud) (2.8.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install twython\n",
    "!pip install textblob\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from PIL import Image\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from textblob import Word, TextBlob\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting row column settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataset: (473, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January 1, 2022 – The Regional Comprehensive E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>January 2, 2022 – Abdalla Hamdok resigns as Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January 4, 2022 – The five permanent members o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>January 5, 2022 – A nationwide state of emerge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>January 6, 2022 – The CSTO deploys a \"peacekee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  January 1, 2022 – The Regional Comprehensive E...\n",
       "1  January 2, 2022 – Abdalla Hamdok resigns as Pr...\n",
       "2  January 4, 2022 – The five permanent members o...\n",
       "3  January 5, 2022 – A nationwide state of emerge...\n",
       "4  January 6, 2022 – The CSTO deploys a \"peacekee..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"WikipediaEvents.csv\", index_col=0)\n",
    "print(\"shape of dataset: {}\" .format(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      January 1, 2022 – The Regional Comprehensive E...\n",
       "1      January 2, 2022 – Abdalla Hamdok resigns as Pr...\n",
       "2      January 4, 2022 – The five permanent members o...\n",
       "3      January 5, 2022 – A nationwide state of emerge...\n",
       "4      January 6, 2022 – The CSTO deploys a \"peacekee...\n",
       "                             ...                        \n",
       "468    October, 2024 – 2024 Georgian presidential ele...\n",
       "469     November, 2024 – 2024 Namibian general election.\n",
       "470    November, 2024 – 2024 Romanian presidential el...\n",
       "471    November, 2024 – Lee Hsien Loong, Prime Minist...\n",
       "472    December, 2024 – 2024 Croatian presidential el...\n",
       "Name: text, Length: 473, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Lowercases, Punctuation, Numbers and Newline Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and preprocess text data.\n",
    "\n",
    "    This function performs several cleaning operations on text data:\n",
    "    - Lowercases the text (Case Folding)\n",
    "    - Removes punctuation\n",
    "    - Removes numbers\n",
    "    - Removes newline characters\n",
    "\n",
    "    Parameters:\n",
    "    text (pandas.Series): A pandas Series containing text data.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: A pandas Series with cleaned text.\n",
    "    \"\"\"\n",
    "    # Lowercasing (Case Folding)\n",
    "    text = text.str.lower()\n",
    "    # Removing punctuations, numbers, and newline characters\n",
    "    text = text.str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    text = text.str.replace(\"\\n\", '', regex=True)\n",
    "    text = text.str.replace('\\d', '', regex=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      january    the regional comprehensive economic...\n",
       "1      january    abdalla hamdok resigns as prime min...\n",
       "2      january    the five permanent members of the u...\n",
       "3      january    a nationwide state of emergency is ...\n",
       "4      january    the csto deploys a peacekeeping mis...\n",
       "                             ...                        \n",
       "468            october    georgian presidential election\n",
       "469                november    namibian general election\n",
       "470           november    romanian presidential election\n",
       "471    november   lee hsien loong prime minister of s...\n",
       "472           december    croatian presidential election\n",
       "Name: text, Length: 473, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"] = clean_text(df[\"text\"])\n",
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/reza/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Remove stopwords from text data.\n",
    "\n",
    "    This function filters out common stopwords from the text data. \n",
    "    Stopwords are removed based on the NLTK's English stopwords list.\n",
    "\n",
    "    Parameters:\n",
    "    text (pandas.Series): A pandas Series containing text data.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: A pandas Series with stopwords removed from the text.\n",
    "    \"\"\"\n",
    "    # Removing stopwords\n",
    "    text = text.apply(lambda x: \" \".join(word for word in str(x).split() if word not in stop_words))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      january regional comprehensive economic partne...\n",
       "1      january abdalla hamdok resigns prime minister ...\n",
       "2      january five permanent members un security cou...\n",
       "3      january nationwide state emergency declared ka...\n",
       "4      january csto deploys peacekeeping mission kaza...\n",
       "                             ...                        \n",
       "468               october georgian presidential election\n",
       "469                   november namibian general election\n",
       "470              november romanian presidential election\n",
       "471    november lee hsien loong prime minister singap...\n",
       "472              december croatian presidential election\n",
       "Name: text, Length: 473, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"] = remove_stopwords(df[\"text\"])\n",
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Rare Words and Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rare Words and Frequent Words\n",
    "def remove_rare_words(df, column_name, n_rare_words=1000):\n",
    "    \"\"\"\n",
    "    Remove rare words from a specified column in a pandas DataFrame.\n",
    "\n",
    "    This function identifies and removes the least frequently occurring words\n",
    "    in the text data. It is useful for removing rare words that might not contribute\n",
    "    significantly to the analysis or modeling.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): A pandas DataFrame containing the text data.\n",
    "    column_name (str): The name of the column in the DataFrame to clean.\n",
    "    n_rare_words (int): The number of least frequent words to remove.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame with rare words removed from the specified column.\n",
    "    \"\"\"\n",
    "    # Identifying the rare words\n",
    "    freq = pd.Series(' '.join(df[column_name]).split()).value_counts()\n",
    "    rare_words = freq[-n_rare_words:]\n",
    "\n",
    "    # Removing the rare words\n",
    "    df[column_name] = df[column_name].apply(lambda x: \" \".join(word for word in x.split() if word not in rare_words))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      january regional economic largest trade area w...\n",
       "1      january resigns prime minister sudan amid prot...\n",
       "2      january five permanent members un security fra...\n",
       "3      january state emergency declared kazakhstan re...\n",
       "4      january deploys mission kazakhstan including r...\n",
       "                             ...                        \n",
       "468               october georgian presidential election\n",
       "469                            november general election\n",
       "470                       november presidential election\n",
       "471    november prime minister singapore since expect...\n",
       "472              december croatian presidential election\n",
       "Name: text, Length: 473, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = remove_rare_words(df, 'text', 1000)\n",
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/reza/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      [january, regional, economic, largest, trade, ...\n",
       "1      [january, resigns, prime, minister, sudan, ami...\n",
       "2      [january, five, permanent, members, un, securi...\n",
       "3      [january, state, emergency, declared, kazakhst...\n",
       "4      [january, deploys, mission, kazakhstan, includ...\n",
       "                             ...                        \n",
       "468          [october, georgian, presidential, election]\n",
       "469                        [november, general, election]\n",
       "470                   [november, presidential, election]\n",
       "471    [november, prime, minister, singapore, since, ...\n",
       "472         [december, croatian, presidential, election]\n",
       "Name: text, Length: 473, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "df[\"text\"].apply(lambda x: TextBlob(x).words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

\section{سوال دوم - عملی}

آیا تا کنون به روند عملکرد بهینه‌سازها فکر کرده‌اید؟ آیا می‌توان آن را یک شبکه‌ی بازرخدادی در نظر گرفت؟ در این پروژه هدف طراحی و پیاده‌سازی یک بهینه‌ساز می‌باشد. برای درک بهتر، توضیحات ریاضیاتی زیر داده می‌شود.



روند یادگیری پارامترهای ($\theta$) یک شبکه عمیق ($f$) با الگوریتم های مرسوم نزول در راستای گرادیان (نظیر \lr{SGD}) را می‌توان به ازای ورودی‌های آموزشی $x$ بصورت رابطه‌ی (۱) در نظر گرفت:

\begin{equation}
	\theta_{i+1} = \theta_i - \alpha \nabla f(x; \theta_i)
\end{equation}

حال اگر فرض شود که به جای نرخ یادگیری ثابت $\alpha$ از یک تابع (شبکه‌ی عمیق) نظیر $g$ با پارامترهای قابل یادگیری $\phi$ استفاده کنیم، می‌توان رابطه‌ی (۱) را بصورت رابطه‌ی (۲) بازنویسی نمود:

\begin{equation}
	\theta_{i+1} = \theta_i + g(\nabla f(x; \theta_i); \phi)
\end{equation}

در نهایت می‌توان پارامتر $\theta_i$ را نیز به عنوان یک ورودی دیگر به $g$ در نظر گرفت و رابطه‌ی (۲) را نیز بصورت زیر بازنویسی کرد:

\begin{equation}
	\theta_{i+1} = g(\nabla f(x; \theta_i), \theta_i; \phi)
\end{equation}

حال می‌توان نتیجه گرفت که اگر تابع $g$ را یک شبکه‌ی بازرخدادی (نظیر \lr{LSTM} یا \lr{GRU}) در نظر گرفت، امکان ارئه‌ی یک بهینه‌ساز وجود دارد، که کل فرایند یاد شده را می‌توان با دو حلقه (بیرونی\footnote{\lr{Outer loop}} و درونی\footnote{\lr{Inner loop}}) انجام داد که معماری کلی آن در ادامه ضمیمه شده است. پیمایش یکبار حلقه‌ی بیرونی معادل است با یک تکرار (\lr{Epoch}) برای آموزش شبکه‌ی $g$ و پیمایش یکبار حلقه درونی معادل است با تولید یک داده آموزشی برای شبکه‌ی $g$.



در این سوال هدف طراحی و پیاده سازی یک بهینه‌ساز بر اساس توضیحات فوق می‌باشد:

\begin{enumerate}
	\item
مجموعه داده اول را به عنوان مجموعه آموزشی در نظر بگیرید، آن را نمایش داده و پس درهم سازی به ۵۰ زیر مجموعه تقسیم کنید بطوریکه در هر مجموعه داده از هر کلاس به تعداد برابر نمونه موجود باشد و انتخاب نمونه‌ها نیز با احتمال یکنواخت صورت گرفته باشد. حال، یک شبکه‌ی \lr{MLP} دلخواه طراحی نمایید و آن را $f$ بنامید که $f_1, f_2, \ldots$ شبکه‌های \lr{MLP} با معماری یکسان هستند و صرفا مقادیردهی اولیه‌ی آن‌ها هر بار متفاوت است.
	
	\begin{qsolve}
مجموعه داده ورودی (\texttt{dataset\_1.csv}) متشکل از نقاط \texttt{x} ،\texttt{y} و \texttt{label} ای است که جدا کننده دو کلاس داده‌ها است. ابعاد این دیتاست $(100000, 3)$ است.
	\end{qsolve}
	
	
	
	\begin{qsolve}
	
		\begin{center}
			\includegraphics*[width=0.4\linewidth]{pics/img1.png}
			\captionof{figure}{خروجی دیتاست \texttt{dataset\_1.csv}}
			\label{خروجی دیتاست ۱}
		\end{center}
		
		رسم گرافیکی دیتاست ورودی به‌صورت زیر است:
		
		\begin{center}
			\includegraphics*[width=0.5\linewidth]{pics/img2.png}
			\captionof{figure}{دیتاست \texttt{dataset\_1.csv}}
			\label{دیتاست ۱}
		\end{center}
		
		سپس طبق صورت مسئله،‌ دیتاست ورودی را به ۵۰ زیردیتاست تقسیم می‌کنیم. سایز زیردیتاست های تولید شده $(2000, 3)$ است. در ادامه خروجی این تقسیم دیتاست آورده شده است:
	\end{qsolve}
	
	
	\begin{qsolve}
		\begin{center}
			\includegraphics*[width=0.5\linewidth]{pics/img3.png}
			\captionof{figure}{زیردیتاست های تولید شده}
			\label{زیردیتاست ۱}
		\end{center}
		
		
		در ادامه شبکه ای \texttt{MLP} با مشخصات زیر تعریف شده است:
		\begin{itemize}
			\item تعداد نرون های ورودی:‌ ۲
			\item تعداد لایه‌های مخفی: ۲
			\item تعداد نرون‌های لایه مخفی اول: ۱۲۸
			\item تعداد نرون‌های لایه مخفی دوم: ۶۴
			\item تعداد نرون‌های خروجی: ۱
			\item تابع فعالساز: \texttt{ReLU}
		\end{itemize}
	\end{qsolve}
	
	
	
	
	\item 
یک شبکه‌ی بازرخدادی مبتنی بر \lr{GRU} طراحی نمایید و آن را $g$ بنامید که وظیفه‌ی آن بهینه‌سازی وزن‌های قابل یادگیری معماری $f$ برای هدف مورد نظر می‌باشد. با استفاده از ۵۰ زیر مجموعه‌ی ایجاد شده در قسمت قبل، شبکه‌ی $g$ را آموزش دهید. روند پیاده‌سازی آموزش، معماری طراحی شده و سایر جزئیات مورد نظر را در گزارش درج نمایید. توجه داشته باشید به ازای هر حلقه‌ی درونی (در هر حلقه‌ی بیرونی)، یک مقداردهی کاملا جدید برای شبکه‌ی $f$ صورت می‌گیرد. در هر زیر مجموعه نسبت آموزش به آزمون ۲:۸ است.


	\begin{qsolve}
	در این قسمت، بهینه‌سازی مبتنی بر شبکه بازرخدادی \texttt{GRU} با مشخصات زیر تعریف می‌کنیم:
		
		\begin{itemize}
			\item سایز ورودی: ۲
			\item سایز لایه مخفی: ۱۲۸
			\item سایز خروجی:‌ ۱
			\item نرخ یادگیری: ۰٫۰۰۱	
		\end{itemize}
		
		سپس شبکه $g$ را با زیرداده های بدست آورده آموزش می‌دهیم و به میانگین دقت و خطای زیر می‌رسیم:
		
		\begin{latin}
			\texttt{Average Accuracy: 49.99}\\
			\texttt{Average Error: 2.2704}
		\end{latin}
	\end{qsolve}






	\item
مجموعه داده‌ی دوم را نیز بارگذاری کرده و آن را نمایش دهید و تفاوت‌های آن را با مجموعه داده‌ی اول بیان کنید. حال آن را به ۳۰ زیر مجموعه همانند توضیحات قسمت ۱ تقسیم کنید. در نهایت، به ازای هر مجموعه داده، یک شبکه با معماری $f$ در نظر گرفته و با شبکه‌ی $g$ آن را بهینه‌سازی کنید. میانگین دقت و خطا را گزارش نمایید.


	\begin{qsolve}
در این قسمت مجموعه داده دوم (\texttt{dataset\_2.csv}) را می‌خوانیم و آن را نمایش می‌دهیم. این دو دیتاست در ظاهر شبیه‌به هم هستند اما ابعاد آنها با هم متفاوت است. 

ابعاد دیتاست \texttt{dataset\_2.csv}، $(60000, 3)$ است.

	\begin{center}
		\includegraphics*[width=0.4\linewidth]{pics/img4.png}
		\captionof{figure}{خروجی دیتاست \texttt{dataset\_2.csv}}
		\label{خروجی دیتاست ۲}
	\end{center}
	
	دیتاست \texttt{dataset\_2.csv} به‌صورت زیر رسم می‌شود:
	
	\begin{center}
		\includegraphics*[width=0.5\linewidth]{pics/img5.png}
		\captionof{figure}{دیتاست \texttt{dataset\_2.csv}}
		\label{دیتاست ۲}
	\end{center}
	\end{qsolve}
	
	
	
	\begin{qsolve}
		در ادامه مشابه با قسمت قبل، دیتاست را می‌بایست به تعدادی زیردیتاست تقسیم کنیم. در این قسمت دیتاست ورودی را به ۳۰ زیردیتاست تقسیم می‌کنیم. ابعاد هر زیردیتاست مشابه با قسمت قبل، $(2000, 3)$ می‌شود.
		
		در ادامه مشابه با قسمت قبل، سعی می‌کنیم با استفاده از بهینه‌ساز $g$ وزن‌های شبکه $f$ را این‌بار با استفاده از دیتاست \texttt{dataset\_2.csv} بهینه‌سازی کنیم.
		
		در این قسمت نیز، از همان تابع $g$ تعریف شده در قسمت قبل استفاده شده است. پس از انجام آموزش، مقدار میانگین خطا و دقت به‌صورت زیر بدست می‌آید:
		
		\begin{latin}
			\texttt{Average Accuracy for dataset\_2: 49.96}\\
			\texttt{Average Error for dataset\_2: 1.8790}
		\end{latin}
		
	\end{qsolve}



	\item
\textbf{(اختیاری)} با مطالعه و تحقیق روشی ارائه دهید تا بتوان عملکرد بهینه‌ساز $g$ را بصورت کمی و کیفی ارزیابی نموده و همچنین بتوان آن را با بهینه‌ساز \lr{ADAM} مقایسه نمود.

\end{enumerate}


\begin{qsolve}
برای ارزیابی بهینه‌ساز $g$ میانگین دقت و خطا یکی از معیار‌های کمی مناسب برای ارزیابی است. همچنین می‌توان همانند سایر بهینه‌ساز ها معیار های کمی دیگری مانند \lr{F1-score }، \lr{AUC-ROC} و ... را به کد اضافه نمود و بر اساس آنها نیز عملکرد بهینه‌ساز را ارزیابی کرد.

همچنین برای مقایسه خروجی‌های بهینه‌سازی که ما نوشته ایم با بهینه‌سازی مانند \lr{Adam} می‌توان شبکه را دوبار با همین دیتاست‌ها یک بار با بهینه‌ساز $g$ و بار دیگر با بهینه‌ساز \lr{Adam} آموزش داد و سپس خروجی‌های آنها که شامل میانگین دقت، خطا، امتیاز \lr{F1} و ... است مقایسه کنیم.

برای مقایسه کیفی نیز می‌توان از نمایش لصری توزیع داده‌های پیش‌بینی شده توسط هر دو بهینه‌ساز استفاده نمود.

همچنین معیاری دیگر برای برای مقایسه، بررسی پایداری بهینه‌ساز نوشته شده توسط ما و بهینه‌ساز \lr{Adam} نسبت به تغییر پارامتر‌های ورودی شبکه و نرخ یادگیری است. مطلوب است بهینه‌ساز در برابر تغییرات پارامتر‌های ورودی شبکه نظیر نرخ یادگیری، تعداد \lr{Epoch} و ... کمترین میزان تغییر و نوسان را داشته باشد.
\end{qsolve}














































%شبکه‌های عمیق از عدم تفسیر‌پذیری رنج می‌برند. تلاش برای حل این مشکل، دو ایده \lr{Deconvolutional} و \lr{Up-convolutional} مظرح شده است. بررسی کنید و توضیح دهید هرکدام از دو روش، به چه صورت منجر به تفسیرپذیری می‌شوند؟
%
%
%
%\begin{qsolve}
%	پیش از توضیح دادن این دو روش که چگونه به تفسیرپذیری کمک می‌کنند، ابتدا این دو روش را مختثرا توضیح می‌دهیم.
%	
%	
%	\begin{enumerate}
%		\item \textbf{شبکه \lr{Deconvolutional} یا \lr{Transposed convolutional layer}: }\\
%در لایه‌های کانولوشن ویژگی‌های مهم تصویر با استفاده از یک کرنل استخراج می‌شود و خروجی به عنوان \lr{Feature map} شناخته می‌شود. ابعاد تصویر (ممکن است) کاهش یابد و اطلاعات مهم تصویر حفظ می‌شود.
%
%
%	\begin{center}
%		\includegraphics*[width=0.6\linewidth]{pics/img4.png}
%		\captionof{figure}{لایه کانولوشن}
%		\label{لایه کانولوشن}
%	\end{center}
%	
%	
%	
%	لایه \lr{Deconvolution} دقیقا برعکس لایه‌های کانولوشنی عمل می‌کند. یعنی از یک \lr{Feature map} می‌توان به تصویر رسید. الگ.ریتم \lr{Deconv} با نگاشت نقشه‌های ویژگی‌ به فضای ورودی، این امکان را فراهم می‌کند 
%
%
%
%
%
%	
%	
%		\item \textbf{\lr{ :Up-Convolution}}
%لایه \lr{Up-convolution} نیز همانند \lr{Deconvolution} ابعاد ورودی را زیاد می‌کند و هدف آن تولید یک تصویر بزرگتر از ورودی آن است.
%
%	\begin{center}
%		\includegraphics*[width=0.6\linewidth]{pics/img5.png}
%		\captionof{figure}{لایه \lr{Up-convolution}}
%		\label{لایه آپ‌کانولوشن}
%	\end{center}
%	\end{enumerate}
%	
%	
%	در بسیاری از مراجه این دو تکنیک را معادل‌با هم می‌گیرند چرا که در هر دو روش هدف افزایش ابعاد ورودی است و این کار دقیقا برعکس کانولوشن انجام می‌شود.
%\end{qsolve}
%
%
%
%
%\begin{qsolve}
%	لایه \lr{Deconvolution} و \lr{Up-convolution}با نمایش نقشه‌های ویژگی به فضای ورودی، به ما امکان می‌دهد ببینیم چه نوع الگوهای ورودی نورون‌های خاصی را فعال می‌کنند. در \lr{Up-convolution} 
%\end{qsolve}
%
%
%
%
%\begin{latin}
%	\begin{thebibliography}{9}
%		\bibitem{ref1}
%		Durall R, Keuper M, Keuper J. Watch your up-convolution: Cnn based generative deep neural networks are failing to reproduce spectral distributions. InProceedings of the IEEE/CVF conference on computer vision and pattern recognition 2020 (pp. 7890-7899).
%		
%	\end{thebibliography} 
%\end{latin}

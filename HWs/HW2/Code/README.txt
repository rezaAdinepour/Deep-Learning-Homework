useful links: 

Q2)
https://medium.com/geekculture/how-does-batch-size-impact-your-model-learning-2dd34d9fb1fa
https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e
https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/
https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/


Q3)
https://towardsdatascience.com/how-do-relu-neural-networks-approximate-any-continuous-function-f59ca3cf2c39
https://www.researchgate.net/figure/Piecewise-linear-activation-functions-ReLU-2-LReLU-3-PReLU-4-and-Maxout-6_fig1_280695837
https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8442618/
https://github.com/meitetsu3/PiecewiseLinearRegression/blob/master/PiecewiseLinearRegression.ipynb

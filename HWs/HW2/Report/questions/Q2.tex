\section{سوال دوم - نظری}
تعیین اندازه دسته (\lr{Batch}) به چه عواملی بستگی دارد و تاثیر آن در روند آموزش شبکه چیست؟فرض کنید که اندازه و سایز هر نمونه از مجموعه داده بگونه ای بزرگ و حجیم است که وقتی اندازه دسته بیش از ۲ باشد، خطای حافظه دریافت می‌شود. (\lr{Out of memory}) چگونه می‌تواند این مشکل و چالش را بدون ارتقای سخت‌افزار حل نمود؟ راهکار مدنظر را معرفی و با جزئیات کامل پیاده سازی کنید.







\begin{qsolve}
	در سیستم‌های یادگیری عمیق، هایپرپارامتر‌های زیادی دخیل هستند، یکی از مهمترین آنها اندازه دسته یا \lr{batch size} است. \cite{ref1} اندازه دسته از این جهت مهم است که زیرا با افزایش اندازه دسته می‌توان سرعت محاسباتی را برای آموزش مدل افزایش داد. اما مشکلی که اندازه دسته بزرگ می‌تواند ایجاد کند عدم آموزش مناسب شبکه است. زیرا اگر اندازه دسته خیلی بزرگ باشد، در فرایند آموزش، داده هایی که در ابتدای دسته وجود داشتند، هنگامی که فرآیند آموزش به انتهای دسته می‌رسد موجب این می‌شود که داده‌های ابتدایی فراموش شود و شبکه در \lr{memorisation} دچار مشکل می‌شود و شبکه به درستی آموزش نمی‌بیند. \cite{ref2}
	
همواره مصالحه ای بین اندازه دسته و سرعت همگرایی وجود دارد. اندازه دسته ای برابر با اندازه کل مجموعه داده ها، همگرایی را تضمین می‌کند اما به قیمت کاهش سرعت فرایند آموزش از طرفی کوچک گرفتن اندازه دسته سرعت همگرایی را بالا می‌برد اما تضمینی برای همگرایی مدل وجود ندارد. \cite{ref2}

بنابر این پیشنهاد می‌شود که از اندازه دسته کوچک شروع به آموزش دادن شود و در حین آموزش کم کم اندازه دسته را افزایش داد. \cite{ref2}

در \cite{ref2} روند تغییر هایپرپارامترهای شبکه مثل نرخ یادگیری و اندازه دسته به صورت زیر پیشنهاد شده است:

\begin{center}
	\includegraphics*[width=1\linewidth]{pics/img6.png}
	\captionof{figure}{روند تغییر پویا هایپرپارامترهای مهم شبکه}
	\label{روند تغییر پویا هایپرپارامترهای مهم شبکه}
\end{center}

	در ادامه مثالی از سرعت همگرا شدن یک شبکه \lr{MLP} که با اندازه دسته های مختلف بر روی دیتاست \lr{MNIST} آموزش داده شده است آورده شده است. در شکل های «\ref{تاثیر اندازه دسته در سرعت همگرایی آموزش} و \ref{تاثیر اندازه دسته در سرعت همگرایی تست شبکه}» نمودار نارنجی رنگ مربوط به اندازه دسته ۶۴، نمودار آبی مربوط به اندازه دسته ۲۵۶ و نمودار بنفش مربوط به اندازه دسته ۱۰۲۴ است. همانطور که توضیح داده شد، سرعت همگرایی با اندازه دسته کوچکتر، بیشتر است.
\end{qsolve}







\begin{qsolve}
	\begin{center}
		\includegraphics*[width=1\linewidth]{pics/img7.png}
		\captionof{figure}{تاثیر اندازه دسته در سرعت همگرایی آموزش}
		\label{تاثیر اندازه دسته در سرعت همگرایی آموزش}
	\end{center}
	
	این قضیه در مورد فاز تست شبکه پس از آموزش نیز صادق است:
	
	\begin{center}
		\includegraphics*[width=1\linewidth]{pics/img8.png}
		\captionof{figure}{تاثیر اندازه دسته در سرعت همگرایی تست شبکه}
		\label{تاثیر اندازه دسته در سرعت همگرایی تست شبکه}
	\end{center}
	
	یکی دیگر از عواملی که در تعیین اندازه دسته مهم است، حافظه سیستمی است که از آن استفاده می‌کنیم. اگر حافظه سیستم‌مان محدود باشد نمی‌توان اندازه دسته را بزرگ گرفت چرا که به هنگام آموزش حافظه سیستم پر خواهد شد و با خطای \lr{out of memory} مواجه خواهیم شد. بنابر این در پاسخ به قسمت دوم سوال می‌توان گفت در صورت مواجه شدن با این خطا می‌بایست اندازه دسته را کوچک تر کنیم. با تکرار و سعی و خطا می‌توان اندازه دسته مناسب برای آنکه حافظه پر نشود را پیدا کرد.
	
	در شکل «» \cite{ref3} می‌توان مثال دیگری از این قضیه را مشاهده کرد.
	
	\begin{center}
		\includegraphics*[width=1\linewidth]{pics/img9.png}
		\captionof{figure}{تاثیر اندازه دسته در سرعت همگرایی تست شبکه \cite{ref3}}
		\label{تاثیر اندازه دسته در سرعت همگرایی تست شبکه}
	\end{center}
	
	
	
	
	\begin{latin}
		\begin{thebibliography}{9}
			\bibitem{ref1}
			Bengio Y. Practical recommendations for gradient-based training of deep architectures. InNeural networks: Tricks of the trade: Second edition 2012 May (pp. 437-478). Berlin, Heidelberg: Springer Berlin Heidelberg.
			
			
			\bibitem{ref2}
			Smith SL, Kindermans PJ, Ying C, Le QV. Don't decay the learning rate, increase the batch size. arXiv preprint arXiv:1711.00489. 2017 Nov 1.
			
			\bibitem{ref3}
			Hoffer E, Hubara I, Soudry D. Train longer, generalize better: closing the generalization gap in large batch training of neural networks. Advances in neural information processing systems. 2017;30.
			
		\end{thebibliography} 
	\end{latin}
\end{qsolve}




















%\textbf{تمامی کدهای سوالات عملی پیوست شده است. همچنین می‌توانید کد‌ها را از گیتهاب بنده به لینک زیر مشاهده و بررسی کنید: }
%
%\begin{latin}
%	\texttt{\href{https://github.com/rezaAdinepour/Deep-Learning-Homework}{github.com/rezaAdinepour/Deep-Learning-Homework}} 
%\end{latin}
%
%\textbf{همچنین به دلیل آنکه تمامی کد ها در فایل های \texttt{notebook} به طور کامل توضیح داده شده است، در این گزارش به دلیل جلوگیری از طولانی شدن آن، از آوردن کد پرهیز کرده ایم.}
%
%
%\begin{qsolve}
%	
%	پس از load کردن دیتاست و تقسیم کردن آن به ۳ دسته آموزش، تست و اعتبار سنجی، آن را رسم کردیم. خروجی به صورت زیر است:
%	
%	\begin{center}
%		\includegraphics*[width=1\linewidth]{pics/img7.png}
%		\captionof{figure}{دیتاست مسئله}
%		\label{دیتاست مسئله}
%	\end{center}
%	
%	همانطور که مشاهده می‌شود، داده ها جداپذیر حطی نیستند پس نمی‌توان به صورت معمولی آن را با شبکه پرسپترون حل نمود. در این سوال تلاش خواهیم کرد با روش‌های معرفی شده در سوال ۱، به صورت عملی با شبکه پرسپترون، یک مسئله غیر خطی را حل نماییم.
%\end{qsolve}
%
%
%
%\begin{enumerate}
%	\item با یک نورون پرسپترونی و صرفا بر اساس ویژگی های ورودی، وزن‌های نورون خود را با آموزش بدست آورید و دسته‌بندی را انجام دهید. و معیار های صحت\footnote{\lr{Accuracy}} و امتیاز F1 را به ازای هر دسته گزارش نمایید. همچنین در نهایت وزن‌های معماری‌تان را به همراه طرحواره آن گزارش کنید.
%	
%	
%	
%	\begin{qsolve}
%		شبکه پرسپترون تک لایه با استفاده از کتابخانه \texttt{PyTorch} تعریف شده است. از تابع Sigmoid به عنوان تابع فعال‌ساز استفاده شده است. در این شبکه از تابع بهینه‌ساز \lr{stochastic gradient descent} استفاده شده است و برای محاسبه خطا، از \lr{mean squared error} به عنوان تابع هزینه استفاده شده است.
%		
%		پس از ۵۰۰ ایپاک آموزش شبکه، خروجی شبکه به صورت زیر شده است:
%		\begin{latin}
%			\texttt{Epoch 500/500, Loss: 0.3373, Accuracy: 0.5263, F1 Score: 0.5115}\\
%			\texttt{---------------------------------------------------------------}\\
%			\texttt{Validation Loss: 0.3900, Validation Accuracy: 0.5173, Validation F1 Score: 0.4689
%			}\\
%			\texttt{---------------------------------------------------------------}
%		\end{latin}
%		
%		همچنین نمودار‌های دقت و خطا بر حسب تعداد \lr{Epoch} به صورت زیر شده است:
%		
%		\begin{center}
%			\includegraphics*[width=1\linewidth]{pics/img8.png}
%			\captionof{figure}{نمودار های خطا و دقت}
%			\label{نمودار های خطا و دقت}
%		\end{center}
%		
%		همانطور که از نمودار ها و خروجی شبکه مشاهده می‌شود، نشان از نوسان بالا در شبکه را دارد که کاملا طبیعیست چرا که داده ها جداپذیر خطی نیستند و شبکه هرچه تلاش می‌کند تا دو کلاس را از هم تفکیک کند نمی‌تواند و دچار نوسان می‌شود. مقدار \lr{Loss} از ۰٫۳ پایین تر نمی‌آید همچنین مشاهده می‌شود دقت روی مجموعه داده اعتبارسنجی بعد از ایپاک ۳۰۰ به شدت افت شده است.
%		
%		
%		ماتریس پراکندگی\footnote{\lr{Confusion matrix}} برای مجموعه داده‌های آموزش، تست و اعتبارسنجی به صورت زیر شده است:
%		
%		\begin{center}
%			\includegraphics*[width=1\linewidth]{pics/img9.png}
%			\captionof{figure}{ماتریس پراکندگی}
%			\label{ماتریس پراکندگی ۱}
%		\end{center}
%	\end{qsolve}
%	
%	
%	
%	
%	
%	
%	
%	\begin{qsolve}
%		از خروجی ماتریس‌های پراکندگی نیز مشاهده می‌شود که تعداد نمونه های که اشتباه شناسایی شده اند (نمونه های روی قطر فرعی) زیاد هستند که نشان از عدم آموزش شبکه دارد.
%		
%		پس از فاز آموزش شبکه، نوبت به تست شبکه آموزش داده شده به وسیله مجموعه داده‌های تست می‌رسد. خروجی شبکه بر روی داده های تست به صورت زیر شده است:
%		
%		\begin{latin}
%			\texttt{Test loss: 0.3493, Test Accuracy: 0.5289, Test F1 Score: 0.5289}
%		\end{latin}
%		
%		وزن‌های نهایی شبکه پس از آموزش به صورت زیر به‌دست آمده است:
%		\begin{latin}
%			\texttt{Final weights: tensor([[ 0.1273, -0.1831]], device='cuda:0')}
%		\end{latin}
%	\end{qsolve}
%	
%	
%	
%	
%	
%	
%	\item به ورودی قسمت قبل، توان بالای ورودی ها تا توان سوم را افزوده و نتیجه حاصل را ضمن گزارش تحلیل نموده و توجیه کنید.
%	
%	\begin{qsolve}
%		در این قسمت، ابتدا توان دوم و سوم ورودی را محاسبه می‌کنیم و هر دو آن را به شبکه می‌دهیم. بر اساس آنچه که در سوال اول توضیح دادیم، ممکن است با به توان رساندن ویژگی های ورودی داده هایی که جداپذیر خطی نیستند، جداپذیر خطی شوند. در این مثال داده هارا پس از به توان رساندن رسم کردیم:
%		
%		\begin{center}
%			\includegraphics*[width=1\linewidth]{pics/img10.png}
%			\captionof{figure}{ویژگی های به توان رسانده شده}
%			\label{ویژگی های به توان رسانده شده}
%		\end{center}
%		
%		همانطور که از «شکل \ref{ویژگی های به توان رسانده شده}» مشاهده می‌شود، توان دوم داده‌های ورودی جداپذیر خطی شده است و امکان حل آن با یک نرون پرسپترون وجود دارد اما توان سوم داده‌های ورودی همچنان جداناپذیر خطی است. توان چهارم نیز تست شد، آن هم جداناپذیر خطی بود اما به دلیل آنکه در صورت سوال خواسته نشده است. گزارش آن آورده نشده است.
%		
%		انتظار داریم اگر به ورودی شبکه، توان دوم داده‌های دیتاست را بدهیم، شبکه بتواند مسئله را حل نماید و مقدار Loss آن مینیمم و Accuracy آن ماکزیمم شود. این‌بار داده‌های جدید را با همان شبکه قبلی مجدد Train می‌کنیم و خروجی‌های آن را گزارش می‌دهیم.
%		
%		پس از آموزش شبکه با ویژگی های جدید، خروجی شبکه به صورت زیر به‌دست آمده است:
%		
%		\begin{latin}
%			\texttt{Epoch 500/500, Loss: 0.0760, Accuracy: 0.9051, F1 Score: 0.8139}\\
%		\end{latin}
%	\end{qsolve}
%	
%	
%	\begin{qsolve}
%		\begin{latin}
%			\texttt{---------------------------------------------------------------}\\
%			\texttt{Validation Loss: 0.1162, Validation Accuracy: 0.7977, Validation F1 Score: 0.7822}\\
%			\texttt{---------------------------------------------------------------}\\
%		\end{latin}
%		
%				مشاهده می‌شود که مقدار Loos گزارش شده بر روی داده های آموزش بسیار کوچکتر از حالت قبل است و تقریبا نزدیک به صفر. همچنین Accuracy شبکه نیز نسبت به حال قبل مقدار ۴۰ درصد افزایش یافته است. مقادیر گزارش شده بر روی داده‌های اعتبارسنجی نیز نسبت به حال قبل بهبود یافته اند.
%		
%		نمودار Loss و Accuracy خروجی شبکه به صورت زیر گزارش می‌شود:
%		\begin{center}
%			\includegraphics*[width=1\linewidth]{pics/img11.png}
%			\captionof{figure}{نمودار‌های خطا و دقت}
%			\label{نمودار‌های خطا و دقت ۲}
%		\end{center}
%		
%		نوسانات کمتری نسبت به قسمت قبل در نمودار Accuracy مشاهده می‌شود و دیگر دقت برای مجموعه داده های اعتبارسنجی افت نکرده است. همچنین مقدار خطا نیز با شیب بیشتری نسبت به حالت قبل کاهش پیدا کرده است.
%		
%		خروجی ماتریس پراکندگی شبکه نیز به صورت زیر است:
%		\begin{center}
%			\includegraphics*[width=1\linewidth]{pics/img12.png}
%			\captionof{figure}{ماتریس پراکندگی}
%			\label{ماتریس پراکندگی ۲}
%		\end{center}
%		
%		مشاهده می‌شود که نمونه های درست طبقه‌بندی شده (نمونه های روی قطر اصلی) نسبت به حال قبل بیشتر است و همچنین نمونه های اشتباه نیز به مراتب کمتر از حالت قبل است.
%		
%	\end{qsolve}
%	
%	
%		
%	\begin{qsolve}
%		خروجی شبکه بر روی مجموعه داده‌های Test به صورت زیر شده است:
%		
%		\begin{latin}
%			\texttt{Test loss: 0.0965, Test Accuracy: 0.8300, Test F1 Score: 0.6127}\\
%		\end{latin}
%		
%		خروجی شبکه بر روی داده های تست نیز بهبود زیادی نسبت به حالت قبل داشته است.
%		
%		همچنین وزن‌های نهایی شبکه به صورت زیر گزارش می‌شود:
%		\begin{latin}
%			\texttt{Final weights: tensor([[-0.0438, -0.0453]], device='cuda:0')}\\
%		\end{latin}
%		
%		
%		مجددا تمام مراحل را برای توان سوم داده‌های ورودی تکرار می‌کنیم. مطابق با «شکل \ref{ویژگی های به توان رسانده شده}» انتظار داریم خروجی شبکه پس از آموزش تقریبا همانند توان اول داده ها باشد، چرا که در هر دو حالت داده‌ها جداناپذیر خطی هستند. خروجی شبکه آموزش دیده بر روی توان سوم داده‌های ورودی به صورت زیر گزارش می‌شود:
%		
%		\begin{latin}
%			\texttt{Epoch 500/500, Loss: 0.4831, Accuracy: 0.4759, F1 Score: 0.3548}\\
%			\texttt{---------------------------------------------------------------}\\
%			\texttt{Validation Loss: 0.4572, Validation Accuracy: 0.5167, Validation F1 Score: 0.3793}
%		\end{latin}
%		
%		با توجه به نتایج بدست آمده، پیش‌بینی ما درست است. چرا که مقدار خطا نسبت به حالت دوم، مجددا افزایش یافته و دقت نیز کاهش یافته است. نمودار های خروجی نیز مطابق با شکل زیر گزارش می‌شود:
%		
%		\begin{center}
%			\includegraphics*[width=1\linewidth]{pics/img13.png}
%			\captionof{figure}{نمودار‌های خطا و دقت}
%			\label{نمودار‌های خطا و دقت ۳}
%		\end{center}
%		
%		از نمودار ها نیز می‌توان نتیجه گرفت که شبکه به درستی آموزش ندیده است چرا که در ۵۰۰ تکرار مقدار خطا خیلی نرم و با شیب کمی کاهش یافته است همچنین مقدار دقت نیز در طول فرایند آموزش تقریبا ثابت بوده است.
%		
%		خروجی ماتریس‌های پراکندگی نیز به صورت زیر گزارش می‌شود:	
%	\end{qsolve}
%	
%	
%	\begin{qsolve}
%		\begin{center}
%			\includegraphics*[width=1\linewidth]{pics/img14.png}
%			\captionof{figure}{ماتریس پراکندگی}
%			\label{ماتریس پراکندگی ۳}
%		\end{center}
%		
%		در این حالت نیز مجددا نمونه های روی قطر غیر اصلی ماتریس افزایش یافته است که نشان از عدم طبقه‌بندی درست مسئله دارد.
%		
%		خروجی شبکه بر روی مجموعه دادگان تست به صورت زیر گزارش می‌شود:
%		\begin{latin}
%			\texttt{Test loss: 0.4470, Test Accuracy: 0.5133, Test F1 Score: 0.3883}\\
%		\end{latin}
%		
%		شبکه بر روی داده‌های تست نیز خروجی مطلوبی ندارد و مقدارLoss و Accuracy آن نسبت به حالت قبل افت کرده است.
%		
%		وزن‌های نهایی شبکه به صورت زیر گزارش می‌شود:
%		
%		\begin{latin}
%			\texttt{Final weights: tensor([[0.0587, 0.1524]], device='cuda:0')}\\
%		\end{latin}
%	\end{qsolve}
%	
%	
%	
%	
%	\item حال حاصل ضرب ورودی‌های قسمت قبل برای مثال \lr{($x_1x_2, x_1x_2^2,x_1^3x_2$)} را به ورودی پرسپترون افزوده و مجددا نتیجه حاصل را ضمن گزارش تحلیل نموده و توجیه کنید. به جهت ریاضیاتی و هندسی، این جمله‌ها بیانگر افزودن چه ویژگی‌هایی هستند؟
%	
%	\begin{qsolve}
%		برای بدست ویژگی های جدید این قسمت، از کلاس \texttt{PolynomialFeatures} در کتابخانه \texttt{sklearn} استفاده کرده ایم. این کلاس ویژگی های ورودی را می‌گیرد و بر اساس درجه ای که برای آن مشخص می‌کنیم، تمام ترکیبات چند جمله ای تا آن درجه را تولید می‌کند. برای مثال اگر ماتریس ویژگی‌های ما به صورت زیر باشد:
%		
%		$$
%		X=\begin{bmatrix} 
%			0 & 1 \\ 
%			2 & 3 \\ 
%			4 & 5 
%		\end{bmatrix}
%		$$
%		
%		با فراخوانی کلاس \texttt{PolynomialFeatures} و فیت کردن داده ها با تابغ \texttt{fit\_transform} به صورت زیر برای ساختن ویژگی‌های چند جمله ای حداکثر تا توان ۲:
%		
%		\begin{latin}
%			\texttt{poly = PolynomialFeatures(degree=2, include\_bias=True)}\\
%			\texttt{X\_poly = poly.fit\_transform(X)}
%		\end{latin}
%		
%		خروجی (ماتریس ویژگی‌های جدید) به صورت زیر خواهد بود:
%	\end{qsolve}
%	
%	
%	
%	
%	
%	\begin{qsolve}
%		$$
%		X_{new}=\begin{bmatrix} 
%			1 & 0 & 1 & 0 & 0 & 1\\
%			1 & 2 & 3 & 4 & 6 & 9\\ 
%			1 & 4 & 5 & 16 & 20 & 25\\ 
%		\end{bmatrix}
%		$$
%		
%		در ويزگی جدید، علاوه بر دو مقدار قبل، در درایه اول هر سطر، بایاس با مقدار ۱ اضاف می‌شود، همچنین در درایه های ۳ تا ۶ در هر سطر، به ترتیب ویژگی های $a^2,ab,b^2$ حساب شده است.
%		
%		تعریف رسمی این کلاس در داکیومنت \texttt{sklearn} به صورت زیر است:
%		
%		\begin{latin}
%			Generate a new feature matrix consisting of all polynomial combinations
%			of the feaxtures with degree less than or equal to the specified degree.
%			For example, if an input sample is two dimensional and of the form
%			[a, b], the degree-2 polynomial features are $[1, a, b, a^2, ab, b^2]$.
%		\end{latin}
%		
%		
%		در این مثال، \texttt{degree} را برابر با ۴ قرار دادیم. یعنی چندجمله‌ای هایی حداکثر تا درجه ۴ را به عنوان ویژگی تولید می‌کنیم. ابعاد دیتاست ورودی مسئله $(4500, 3)$ است. پس از تولید ویژگی های جدید ابعاد مسئله به $(4500, 15)$ افزایش می‌یابد. بنابر این تعداد نورون های ورودی مسئله نیز از ۳ عدد به 15 افزایش پیدا می‌کند و وزن‌های نهایی باید شامل ۱۵ عدد وزن باشد.
%		
%		فضای جدید ویژگی ها را به صورت ۲بعدی و ۳ بعدی رسم کرده‌ایم و خروجی‌آن به صورت زیر شده است:
%		
%		\begin{center}
%			\includegraphics*[width=1\linewidth]{pics/img15.png}
%			\captionof{figure}{فضای جدید ویژگی‌ها}
%			\label{فضای جدید ویژگی‌ها}
%		\end{center}
%		
%		همانطور که مشاهده می‌شود، ویژگی های جدید بدست آمده جداناپذیر خطی هستند و انتظار داریم با آموزش شبکه بر روی این ویژگی ها، خروجی ای همانند حالت توان سوم ویژگی‌ها حاصل شود و شبکه به درستی آموزش نبیند.
%		
%		به این دلیل داده ها در توان‌های بالا جداناپذیر خطی می‌شوند که مقدار اغلب داده‌های خام کوچکتر از ۱ هستند. به همین دلیل توان‌های بالای آنها مقدار بسیار کوچکی می‌شود و باعث فشرده شدن و روی هم افتادن داده‌ها می‌شود. اگر بخواهیم از داده‌های خطی برای حل مسائل غیرخطی استفاده کینم، طبیعتا نباید انتظار داشت خروجی مطلوبی حاصل شود. ورودی‌های توان بالا و چند‌جمله‌ای ها این امکان را برای شبکه فراهم می‌کنند تا تلاش کند با داده‌های غیر خطی (توان‌های دوم و سوم ورودی و حاصل ضرب آنها) آموزش ببیند تا شاید بتواند مسئله غیر‌خطی‌مان را حل نماید.
%		
%برای آنکه مطمئن شویم، شبکه را با داده‌های جدید Train می‌کنیم و خروجی را گزارش می‌کنیم.
%		
%خروجی شبکه پس از آموزش با داده‌های جدید به صورت زیر است:
%	\end{qsolve}
%	
%	
%	
%	\begin{qsolve}
%		\begin{latin}
%			\texttt{Epoch 500/500, Loss: 0.4888, Accuracy: 0.4949, F1 Score: 0.3850}\\
%			\texttt{---------------------------------------------------------------}\\
%			\texttt{Validation Loss: 0.5167, Validation Accuracy: 0.4607, Validation F1 Score: 0.3520}\\
%			\texttt{---------------------------------------------------------------}
%		\end{latin}
%		
%از نتایج مشخص است که شبکه نتوانسته به درستی آموزش ببیند و مقدار Loss و Accuracy بدست آمده تقریبا همانند قسمت اول (آموزش با داده‌های خام) است. نمودار‌های Loss و Accuracy نیز این حرف را توجیه می‌کنند٫ چرا که بسیار نوسانی بوده و مقادیر آنها از یک حد کمتر یا بیشتر نشده است و این امر نشان از عدم آموزش صحیح شبکه دارد. خروجی نمودار های به صورت زیر گزارش می‌شود:
%
%	\begin{center}
%		\includegraphics*[width=1\linewidth]{pics/img16.png}
%		\captionof{figure}{نمودار‌های خطا و دقت}
%		\label{نمودار‌های خطا و دقت ۴}
%	\end{center}
%	
%	ماتریس پراکندگی داده ها به صورت زیر گزارش می‌شود:
%	
%	\begin{center}
%		\includegraphics*[width=1\linewidth]{pics/img17.png}
%		\captionof{figure}{ماتریس پراکندگی}
%		\label{ماتریس پراکندگی ۴}
%	\end{center}
%	
%	همچنین تست شبکه بر روی مجموعه داده‌های تست و وزن‌های نهایی شبکه نیز به صورت زیر گزارش می‌شود:
%	
%	\begin{latin}
%		\texttt{Test loss: 0.5271, Test Accuracy: 0.4556, Test F1 Score: 0.3718}\\
%		\texttt{Final weights: tensor([[-0.0076,  0.1363,  0.1950, -0.0310,  0.1818, -0.0550, -0.1191,  0.0098, -0.0858,  0.2467,  0.2740,  0.1114, -0.0028,  0.1657, -0.1999]], device='cuda:0')}\\
%	\end{latin}
%		
%	\end{qsolve}
%	
%	
%\end{enumerate}
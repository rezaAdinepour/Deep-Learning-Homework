\section{سوال اول - عملی}

فرض کنید یک مجموعه داده دو کلاسه در اختیار دارید که کاملا به صورت خطی کلاس‌ها از هم جداپذیر هستند. یک شبکه چند لایه پرسپترونی (با طراحی دلخواه) طراحی نموده‌اید که لایه خروجی آن شامل دو نرون می‌باشد که تابع فعال‌ساز \texttt{softmax} بر آن اعمال می‌شود. در زمان آموزش، از تابع خطای \texttt{entropy cross binary} برای محاسبه خطا و بهینه‌سازی وزن ها استفاده می‌شود. آیا این امکان وجود دارد که خطای حاصل صفر شود؟ اگر امکان ندارد، با استدلال و اثبات ریاضی نشان دهید و اگر امکان دارد، با معرفی چهار داده (دو داده به ازای هر کلاس) و پرسپترون مد نظرتان نشان دهید که خطا می‌تواند دقیقا صفر شود.


\begin{qsolve}
	در این سوال برای تولید دیتا از تابع \texttt{make\_blobs} از کتابخانه \texttt{sklearn} به صورت زیر استفاده شده است:‌
	
	\begin{latin}
		\texttt{x, y = datasets.make\_blobs(n\_samples=200, centers=[(-1, -1), (1, 1)], cluster\_std=0.5)}
	\end{latin}
	
	که داده هایی با تعداد ۲۰۰ نمونه و انحراف معیار ۰٫۵ حول نقطه های (1-,1-) و (۱و۱) می‌کند که کاملا جداپذیر خطی است «شکل \ref{داده‌های تولید شده برای مسئله}»
	
	\begin{center}
		\includegraphics*[width=1\linewidth]{pics/img1.png}
		\captionof{figure}{داده‌های تولید شده برای مسئله}
		\label{داده‌های تولید شده برای مسئله}
	\end{center}
	
	
	برای حل این مسئله از شبکه‌ی پرسپترونی چند لایه ای با ساختار «شکل \ref{ساختار شبکه طراحی شده در سوال ۱}» استفاده شده است. با توجه به اینکه داده‌ها جداپذیر خطی هستند، می‌توان این مسئله را با یک نرون پرسپترونی نیز حل نمود اما با توجه به اینکه در صورت سوال گفته شده است شبکه ای چند لایه طراحی کنید، از شبکه چند لایه پرسپترونی استفاده کردیم.
\end{qsolve}




\begin{qsolve}
	\begin{center}
		\includegraphics*[width=0.5\linewidth]{pics/img2.pdf}
		\captionof{figure}{ساختار شبکه طراحی شده}
		\label{ساختار شبکه طراحی شده در سوال ۱}
	\end{center}
	
	تابع فعال‌ساز لایه مخفی، \texttt{ReLU} درنظر گرفته شده است و در لایه خروجی نیز از \texttt{softmax} استفاده شده است. طبق خواسته مسئله، از \textbf{entropy cross binary} به‌عنوان تابع خطا استفاده شده است. همچنین از تابع بهینه‌ساز \texttt{ADAM} در این مسئله استفاده شده است.
	
	نتایج آموزش در ۲۰۰ دوره آموزشی به صورت زیر گزارش می‌شود:
	
	\begin{center}
		\includegraphics*[width=1\linewidth]{pics/img3.png}
		\captionof{figure}{منحنی خطا و دقت برای داده‌های آموزش و تست}
		\label{منحنی خطا و دقت برای داده‌های آموزش و تست}
	\end{center}
	
	\begin{center}
		\includegraphics*[width=0.5\linewidth]{pics/img4.png}
		\captionof{figure}{ماتریس پراکندگی}
		\label{ماتریس پراکندگی سوال ۱}
	\end{center}
	
	
\end{qsolve}




%
%\begin{center}
%	\includegraphics*[width=1\linewidth]{pics/img1.png}
%	\captionof{figure}{مسئله مورد بحث}
%	\label{مسئله مورد بحث در سوال۱}
%\end{center}
%
%
%
%\begin{enumerate}
%	\item شکل \lr{a-1} را برای دسته بندی مسئله دودویی درنظر بگیرید. معماری نورون مورد نظر را توضیح داده و وزن‌های آن را بدست آورید.
%	
%	\begin{qsolve}
%		به دلیل آنکه داده های این قسمت جداپذر خطی هستند، می‌توان برای طبقه بندی آنها، از شبکه پرسپترون تک لایه استفاده کرد.
%		
%		معماری این شبکه به صورت «شکل \ref{معماری شبکه پرسپترون تک لایه}» است.
%		
%		
%		\begin{center}
%			\includegraphics*[width=0.8\linewidth]{pics/img2.pdf}
%			\captionof{figure}{معماری شبکه پرسپترون تک لایه}
%			\label{معماری شبکه پرسپترون تک لایه}
%		\end{center}
%	\end{qsolve}
%	
%	\begin{qsolve}
%				در این شبکه، ورودی/خروجی ها با مربع های نارنجی، نورون ها با دایره سبز و تابع فعال ساز با مربع آبی نشان داده شده است. تعداد دیتا ورودی شبکه ۲ است. $x_1$ و $x_2$. بایاس این شبکه با $x_0$ نشان داده شده است. وزن های شبکه نیز با $w$ نشان داده شده است. بنابر این بردار ورودی و وزن‌های شبکه به صورت زیر است:
%		
%		$$
%			X=\begin{bmatrix}          
%				x_0=1\\
%				x_1\\
%				x_2
%				
%				\end{bmatrix} \\\       W=\begin{bmatrix}          
%												w_0\\
%												w_1\\
%												w_2
%											
%											\end{bmatrix}
%		$$
%		
%		طبق تئوری شبکه‌های عصبی می‌دانیم خروجی نرون به صورت زیر محاسبه می‌شود: (در اینجا برای انجام محاسبات ساده، تابع فعال‌ساز درنظر گرفته نشده است)
%		
%		$$
%			\hat{y}=W^T X = \sum_{i=0}^{2} {w_ix_i}=w_0x_0+w_1x_1+w_2x_2 \xrightarrow{x_0=1} w_0+w_1x_1+w_2x_2
%		$$
%		
%		طبق شکل \lr{a-1} دو نقطه از خط جدا کننده دو کلاس را داریم. بنابراین می‌توان معادله خط را به صورت زیر نوشت.
%		
%		می‌دانیم معادله خط به صورت زیر تعریف می‌شود:
%		$$
%			y-y_0=m(x-x_0)
%		$$
%		
%		که در آن $m$ شیب خط است و به صورت زیر $\frac{\Delta y}{\Delta x}$ تعریف می‌شود. با جاگذاری یک از نقاط در معادله خط، می‌توان معادله خط را بدست آورد.
%		
%		$$
%			P_1=\begin{bmatrix}          
%				2.5\\
%				0
%				
%			\end{bmatrix} \\\       P_2=\begin{bmatrix}          
%				0\\
%				2.8
%				
%			\end{bmatrix}
%		$$
%		
%		$$
%			m=\frac{2.8-0}{0-2.5}=-1.12 \rightarrow y-0=-1.12(x-2.5) \rightarrow \boxed{y=-1.12x+2.8}
%		$$
%		
%		حالا اگر معادله خروجی نورون را به صورت زیر مرتب کنیم، می‌توان از مقایسه با مقادله خط بدست آمده وزن‌های شبکه را تعیین کرد.
%		
%		\begin{eqnarray*}
%			x_1=\frac{-w_2}{w_1}x_2-\frac{w_0}{w_1},
%			&x_2=\frac{-w_1}{w_2}x_1-\frac{w_0}{w_2}&
%		\end{eqnarray*}
%
%		
%		در اینجا به دلیل آنکه دو معادله و ۳ مجهول ($w_0,w_1,w_2$) داریم، نیاز است که یکی از وزن ها را فرض کرده و دو وزن دیگر را بدست آورد.
%		
%		\begin{eqnarray*}
%			\frac{-w_2}{w_1}=-1.12 \rightarrow w_2=1.12w_1\\
%			\frac{-w_0}{w_1}=2.8 \rightarrow w_0=-2.8w_1\\
%			\rightarrow
%			\begin{cases}
%				w_2-1.12w_1=0\\
%				-2.8w_1-w_0=0 
%			\end{cases}
%			\text{assume} &w_0&=2.8 \rightarrow \text{\hl{$w_1=-1$}}, \text{\hl{$w_2=-1.12$}}
%		\end{eqnarray*}
%		ذکر این نکته الزامیست که این جواب، یکتا نمی‌باشد و برحسب اینکه مقدار $w_0$ را چه انتخاب کنیم، مقدار ۲ وزن دیگر متفاوت می‌شود.
%	\end{qsolve}
%	
%	
%
%	
%	\item حال شکل \lr{b-1} را درنظر بگیرید. چرا مسئله جداپذیر خطی نیست؟ چگونه می‌توان آن را در قالب حل چند مسئله خطی حل نمود؟ معماری پیشنهادی خودتان را رسم و وزن‌های موجود در آن را با انجام محاسبات بدست آورید. معماری شما می‌تواند حاصل از کنار هم چیدن و پشت هم چیدن یک یا چند نورون پرسپترونی باشد.
%	
%	
%	
%	\begin{qsolve}
%		به مسائلی جداپذیر خطی گفته می‌شود که بتوان داده‌ها (کلاس‌ها) را با استفاده از فقط یک خط از هم جدا کرد. در این مثال، دو کلاس آبی و سبز را نمی‌توان فقط با یک خط از هم جدا کرد. بنابراین این مسئله \textbf{جداپذیر خطی نمی‌باشد.} برای حل این مسئله، چندین روش وجود دارد که در ادامه آنها را توضیح خواهم داد.
%		
%		\begin{enumerate}
%			\item \textbf{افزایش ابعاد ویژگی های مسئله: }\\
%			یعنی در این مثال که مسئله مورد بحث ما دو بعدی است، یک بعد به آن اضاف کنیم و آن را به عنوان یک مسئله ۳ بعدی حل کنیم و تلاش کنیم که یک صفحه برای جدا کردن دو کلاس پیدا کنیم.
%			
%			\item \textbf{دادن ورودی هایی با توان بالا به عنوان ورودی شبکه: }\\
%			در صورتی می‌توان از این روش استفاده کرد که مقدار دقیق تمام نمونه ها را داشته باشیم. در این صورت می‌توان ورودی ها را به توان های بالا (۲ و ۳ و...) رساند و امیدوار باشیم فضای قرارگیری ویژگی های جدید در صفحه به صورت جداپذیر خطی باشد. «این کار در سوال دوم همین سری تمرین انجام شده است و با به توان ۲ رساندن ویژگی های ورودی شبکه، مسئله ای که جداپذیر خطی نبود به جداپذیر خطی تبدیل می‌شود.» در این مسئله به دلیل نداشتن موقعیت دقیق نمونه های هرکلاس نمی‌توان از این روش استفاده کرد.
%			
%			\item \textbf{اضاف کردن لایه مخفی: }\\
%			در اضاف کردن تعداد لایه های مخفی شبکه، آزاد هستیم اما باید به این نکته توجه داشت که اگر بیشتر از یک لایه مخفی به شبکه اضاف کنیم، حل مسئله از نظر خطی بودن خارج شده و نواحی تصمیم گیری شامل خط راست نمی‌شود و نواحی پیچیده تری مانند منحنی ها را در بر می‌گیرد. اما اگر فقط یک لایه مخفی ۳ نورونی به شبکه اضاف کنیم، می‌توان مسئله ای که ذاتا جدا‌پذیر خطی نیست را به وسیله ۳ خط جدا کننده که تعداد این خط ها برابر است با تعداد نورون های لایه مخفی، حل نمود. ساختار این مدل در «شکل \ref{معماری شبکه ۳ لایه پیشنهادی}» آورده شده است.
%			
%			اما مشکلی که وجود دارد آن است که در صورت سوال از ما خواسته شده وزن های شبکه را بدست آوریم، اگر از این ساختار برای حل استفاده کنیم، به دلیل نداشتن مقدار ورودی ها نمی‌توان ۳ وزن لایه متصل به خروجی را بدست آورد.
%			
%			\item \textbf{شکستن مسئله به ۳ زیرمسئله خطی}: \\
%			برای حل این سوال از این روش استفاده شده است. در قسمت قبل دیدیم که یک نورون پرسپترونی می‌تواند یک خد جدا کننده در صفحه رسم کنید. در این مثال، برای جدا کردن این دو کلاس به ۳ خط نیاز داریم. پس داده‌های ورودی مسئله را به ۳ بخش جدا‌پذیر خطی تقسیم می‌کنیم. «شکل \ref{داده های شکسته شده به سه بخش}» اکنون می‌توان همانند قسمت قبل، وزن ها را برای هر سه زیر‌مسئله بدست آورد. در این قسمت ساختار و معماری شبکه همان ساختار قسمت \lr{a-1} است. «شکل \ref{معماری شبکه پرسپترون تک لایه}»
%			
%			
%		\end{enumerate}
%	\end{qsolve}
%	
%	
%	
%	\begin{qsolve}
%		\begin{center}
%			\includegraphics*[width=0.5\linewidth]{pics/img3.pdf}
%			\captionof{figure}{معماری شبکه ۳ لایه پیشنهادی}
%			\label{معماری شبکه ۳ لایه پیشنهادی}
%		\end{center}
%		
%		\begin{center}
%			\includegraphics*[width=1\linewidth]{pics/img4.pdf}
%			\captionof{figure}{داده های شکسته شده به سه بخش}
%			\label{داده های شکسته شده به سه بخش}
%		\end{center}
%		
%		
%		زیر مسئله شماره ۱ در قسمت قبل حل شده است و وزن های آن به صورت زیر بدست آورده شد:
%		\begin{eqnarray*}
%			w_0=2.8, &w_1=-1, &w_2=-1.12
%		\end{eqnarray*}
%		
%		برای دو زیر مسئله دیگر هم، همانند قسمت قبل وزن‌ها را بدست می‌اوریم.
%		
%		\begin{eqnarray*}
%			P_1=\begin{bmatrix}
%				2.5\\
%				0
%			\end{bmatrix}
%			P_2&=&\begin{bmatrix}
%				-1.5\\
%				1.7
%			\end{bmatrix}
%			\rightarrow m=\frac{\Delta y}{\Delta x}=\frac{y_2-y_1}{x_2-x_1}=\frac{-1.5-2.5}{-1.7-0}=\frac{-4}{-1.7}=\boxed{2.35}\\
%			y-0&=&2.35(x-2.5)\rightarrow \boxed{y=2.35x-5.88}\\
%			\rightarrow x_1&=&\frac{-w_2}{w_1}x_2-\frac{w_0}{w_1} \rightarrow \begin{cases}
%				\frac{-w_2}{w_1}=2.35 \rightarrow w_2=-2.35w_1\\
%				\frac{-w_0}{w_1}=-5.88 \rightarrow w_0=5.88w_1 
%			\end{cases}\\
%			\text{Assume}\qquad w_0&=&5.88 \rightarrow \text{\hl{$w_1=1$}}, \text{\hl{$w_2=-2.35$}}
%		\end{eqnarray*}
%	\end{qsolve}
%	
%	
%	
%	
%	
%	
%	\begin{qsolve}
%		\begin{eqnarray*}
%			P_1=\begin{bmatrix}
%				-1.5\\
%				-1.7
%			\end{bmatrix}
%			P_2&=&\begin{bmatrix}
%				0\\
%				2.8
%			\end{bmatrix}
%			\rightarrow m=\frac{\Delta y}{\Delta x}=\frac{y_2-y_1}{x_2-x_1}=\frac{0+1.5}{2.8+1.7}=\frac{1.5}{4.5}=\boxed{0.33}\\
%			y-2.8&=&0.33(x-0)\rightarrow \boxed{y=0.33x+2.8}\\
%			\rightarrow x_1&=&\frac{-w_2}{w_1}x_2-\frac{w_0}{w_1} \rightarrow \begin{cases}
%				\frac{-w_2}{w_1}=0.33 \rightarrow w_2=-0.33w_1\\
%				\frac{-w_0}{w_1}=2.8 \rightarrow w_0=-2.8w_1 
%			\end{cases}\\
%			\text{Assume}\qquad w_0&=&2.8 \rightarrow \text{\hl{$w_1=-1$}}, \text{\hl{$w_2=0.33$}}
%		\end{eqnarray*}
%	\end{qsolve}
%	
%	
%	
%	
%	
%	
%	
%	
%	\item  شگرد هسته\footnote{\lr{Kernel trick}} چیست و چگونه می‌توان قسمت قبل را با آن حل نمود؟ توضیح دهید.
%	
%	\begin{qsolve}
%		این تکنیک به عنوان یکی از روش های حل مسئله قبل معرفی شد و توضیح مختصری در مورد آن داده شد. در این قسمت توضیخات کامل آن را بیان خواهیم کرد.
%		
%		روش شگرد هسته، یکی از چندین روش موجود برای حل مسائل جداناپذیر خطی با روش های خطی است. بدین صورت که اگر ابعاد ویژگی های مسئله را R در نظر بگیریم و داده ها در R بعد جداناپذیر خطی باشند، ممکن است با افزایش بعد ویژگی ها (R+n) و اضاف کردن ویژگی ای جدید، داده ها جداپذیر خطی شوند و بتوان مسئله را با یک شبکه خطی حل نمود.
%		
%		در این سوال، ویژگی های ورودی ۲ بعدی هستند و داده ها در ۲ بعد جداناپذیر خطی هستند. بنابر این می‌توان یک ویژگی جدید در بعد سوم به ورودی ها اضاف کرد و خروجی را نمایش داد تا شاید داده ها جدا‌پذیر خطی شوند.
%		
%		این کار را انجام دادیم و اثباط کردیم که با افزایش بعد این مسئله، داده ها جداپذیر خطی می‌شوند. شکل زیر را به عنوان داده های ورودی مسئله در نظر بگیریم:
%		
%		\begin{center}
%			\includegraphics*[width=0.6\linewidth]{pics/img5.png}
%			\captionof{figure}{داده های ورودی مسئله در ۲ بعد}
%			\label{داده های ورودی مسئله در ۲ بعد}
%		\end{center}
%		
%		برای افزودن بعد سوم به این داده های ۲ بعدی، تابع زیر را نوشته ایم.
%	\end{qsolve}
%	
%	
%	\begin{qsolve}
%		
%		\begin{latin}
%			\texttt{def kernel\_trick(x):}\\
%			\texttt{return np.append(x, np.expand\_dims(x[:, 0]**2 ** x[:, 1]**2, axis=1), axis=1)}
%		\end{latin}
%		
%		این تابع ویژگی جدید ${(x_0^2)}^{x_1^2}$ را به داده های ورودی به عنوان بعد سوم اضافه می‌کند. بنابر در فضای ویژگی جدید، هر نقطه از بردار ویژگی شامل ۳ عضو است. (\textbf{این نکته لازم به ذکر است که ویژگی جدید تولید شده، با سعی و خطا بدست آمده است و می‌توان به جای آن هر ویژگی جدید دیگری را قرار داد})
%		
%		
%		پس از رسم فضای ویژگی جدید، مشاهده می‌شود که داده ها جداپذیر خطی شده اند و می‌توان آنها را با یک صفحه از هم جدا نمود.
%		
%		\begin{center}
%			\includegraphics*[width=0.8\linewidth]{pics/img6.png}
%			\captionof{figure}{فضای ویژگی های جدید در ۳ بعد}
%			\label{فضای ویژگی های جدید در ۳ بعد}
%		\end{center}
%	\end{qsolve}
%\end{enumerate}
%
%
%
%	
%
%		
%		
%		
%		
%			
%		
%		
%		
%		
%		
%			
%		
%		
%		
%		
%
%		
%	
%	
%	
%
%	
%	
%	
%	
%
%	
%	
%	
%	
%	
%	
%	
%	
%	
%	
%	
%	
%
%
%
%
%
%
%
%
%
%
%
%
%%
%%
%%
%%
%%
%%
%%
%%\begin{qsolve}[]
%%	\begin{eqnarray*}
%%		p(t)&=&\sum_{n=-\infty}^{\infty}\delta(t-nT)\qquad \text{\lr{periodic in T}}\\
%%		a_k &=&\frac{1}{T}\int_{-T/2}^{T/2}f(t)e^{jk(2\pi/T)t}dt=
%%		\frac{1}{T}\int_{-T/2}^{T/2}\sum_{n=-\infty}^{\infty}\delta(t-nT)e^{jk(2\pi/T)t}dt
%%		\xrightarrow{n=0}\\
%%		&=&\frac{1}{T}\int_{-T/2}^{T/2}\delta(t)e^{jk(2\pi/T)t}dt=\frac{1}{T}
%%		\hspace{8em}\text{\hl{$a_k=\frac{1}{T}$}}
%%	\end{eqnarray*}
%%	تابع متناوب است و سری فوریه دارد، پس تبدیل فوریه آن همان سری فوریه آن به صورت
%%	جمع ضربه هاست.
%%	\begin{eqnarray*}
%%		P(j\omega)&=&\mathcal{F}\left\{\sum_{k=-\infty}^{\infty}a_ke^{jk(2\pi/T)t}\right\}=\sum_{k=-\infty}^{\infty}2\pi a_k\delta(\omega-k\frac{2\pi}{T})
%%		=\frac{2\pi}{T}\sum_{k=-\infty}^{\infty}\delta(\omega-k\frac{2\pi}{T})
%%	\end{eqnarray*}
%%\end{qsolve}
%%
%%با توجه به اینکه با استفاده از این سیگنال نمونه برداری قطار ضربه از یک سیگنال پیوسته زمان انجام میدهیم و با استفاده نتیجه بدست آمده در قسمت
%%قبل تبدیل فوریه سیگنال بدست آمده حاصل از ضرب این سیگنال در سیگنال دلخواه $x(t)$ را بدست آورید.
%%
%%\begin{qsolve}[]
%%	\begin{eqnarray*}
%%		x_p(t)&=&x(t)\times p(t)\Rightarrow X_p(j\omega)=\frac{1}{2\pi}X(j\omega)*P(j\omega)
%%		=\frac{1}{2\pi}\convolve[\omega]{P}{X}\\
%%		X_p(j\omega)&=&\frac{1}{2\pi}\sum_{k=-\infty}^{\infty}\intinf \frac{2\pi}{T}\delta(\tau-k\frac{2\pi}{T})X(j(\omega-\tau))d\tau
%%		=\frac{1}{T}\sum_{k=-\infty}^{\infty}X(j(\omega-k\frac{2\pi}{T}))
%%	\end{eqnarray*}
%%\end{qsolve}
%%
%%حال نتیجه بدست آمده از قسمت قبل را با تبدیل فوریه گسسته سیگنال نمونه برداری شده $x[n]=x(nT)$ مقایسه کنید. حال شرطی روی نرخ
%%نمونه برداری $F_s=\frac{1}{T_s}$ بدست آورید که تمام محتوای فرکانسی سیگنال اولیه پس از نمونه برداری حفظ شود. (شرط نایکوییست)
%%
%%\begin{qsolve}[]
%%	پاسخ بدست آمده متناوب است، پس میتوان آن را به صورت یک سری فوریه نوشت.
%%	یعنی داریم که : $X(j\omega)=\sum_{n=-\infty}^{\infty}C_ke^{jk\omega_0\omega}$
%%	\splitqsolve
%%	\begin{eqnarray*}
%%		X_p(j\omega)&=&\frac{1}{T}\sum_{k=-\infty}^{\infty}X(j(\omega-k\frac{2\pi}{T}))
%%		\xrightarrow{\text{\lr{periodic in $\frac{2\pi}{T}$}}}\sum_{n=-\infty}^{\infty}C_ne^{jnT\omega}\\
%%		C_n&=&\frac{1}{2\pi/T}\int_{-\pi/T}^{\pi/T}X_p(j\omega)e^{jnT\omega}d\omega
%%		=\frac{T}{2\pi}\int_{-\pi/T}^{\pi/T}\frac{1}{T}\sum_{k=-\infty}^{\infty}X(j(\omega-k\frac{2\pi}{T}))e^{jnT\omega}d\omega\\
%%		&=&\xrightarrow{k=0}\frac{1}{2\pi}\int_{-\pi/T}^{\pi/T}X(j\omega)e^{jnT\omega}d\omega
%%	\end{eqnarray*}
%%	حال اگر داشتیم که $X(j\omega)\{|\omega|\leq\frac{\pi}{T}\}=0$
%%	\begin{eqnarray*}
%%		C_n&=&\frac{1}{2\pi}\int_{-\pi/T}^{\pi/T}X(j\omega)e^{jnT\omega}d\omega=
%%		\frac{1}{2\pi}\int_{-\infty}^{\infty}X(j\omega)e^{jnT\omega}d\omega=x(nT)\\
%%		X_p(j\omega)&=&\sum_{n=-\infty}^{\infty}C_ne^{jnT\omega}=\sum_{n=-\infty}^{\infty}x(nT)e^{jnT\omega}
%%		=\sum_{n=-\infty}^{\infty}x[n]e^{jnT\omega}=X(e^{j\Omega})\when_{\Omega=\omega T}
%%	\end{eqnarray*}
%%	که این به ما شرط نایکوییست را میدهد. به صورتی که:
%%	\[
%%		\text{ : اگر داشته باشیم}
%%        \forall \omega \geq \omega_s = \frac{\pi}{T}: X(j\omega)=0\Longrightarrow X_p(j\omega)=X(e^{j\Omega})\when_{\Omega=\omega T}
%%	\]
%%\end{qsolve}
%%
%%فرض کنید به علت محدودیت هایی که داریم شرط نایکوییست برقرار نباشد در این حالت روشی پیشنهاد دهید که محتوای فرکانسی کمتری از سیگنال
%%در اثر نمونه برداری از بین برود.
%%
%%\begin{qsolve}[]
%%    ناچار ایم که مقداری اطلاعات از دست بدهیم، زیرا در حالت خالص نمونه برداری، شرط نایکوییست برقرار نیست 
%%    و دچار اعوجاج فرکانسی هستیم.
%%
%%    میتوانیم قبل از نمونه برداری اطلاعات فرکانسی را کم کنیم، اینگونه اطلاعات از بین رفته و 
%%    فرکانسی اطلاعات کاهش میابد، ولی حداقل اعوجاج فرکانسی نداریم و نویز با فرکانس پایین ایجاد نمیکنیم.
%%
%%    به این کار Anti-Aliasing میگوییم. به این صورت که قبل از نمونه برداری، یک \lr{low-pass filter} استفاده میکنیم.
%%
%%    \begin{center}
%%        \includegraphics*[width=0.8\linewidth]{pics/anti-aliasing.png}
%%        \captionof{figure}{\lr{anti aliasing diagram}}
%%    \end{center}
%%\end{qsolve}
\section{سوال پنجم - عملی}
ابروضوح یک کاربرد در بینایی کامپیوتر می‌باشد که در آن هدف ارتقای وضوح تصاویر می‌باشد. این امر می‌تواند در مقاصد مختلف نظیر تصویر برداری پزشکی، بهبود تصاویر نظارتی-امنیتی، بازسازی تصاویر قدیمی و ... به‌کار گرفته شود. در این سوال هدف طراحی و پیاده سازی یک شبکه عصبی چند‌لایه برای هدف فوق می‌باشد.



\begin{enumerate}
	\item ۱۰ تصویر دلخواه از اینترنت که حاوی گستره رنگی مختلفی می‌باشد را به‌عنوان مجموعه داده انتخاب کنید و آن را نمایش دهید. حال وضوح هر یک از تصاویر را نصف کنید. اکنون به ازای هر یک از پیکسل ها در عکس اصلی، متناظر آن و هشت همسایگی مجاور آن در عکس با وضوح پایین تر را بیابید و مجموعه داده موردنظر را بدست آورید. ابعاد ورودی برابر با ۲۷ ویژگی (پیکسل متناظر و هشت همسایگی آن به ازای سه کانال رنگی در وضوح پایین) خواهد بود و خروجی (لیبل) نیز شامل سه مقدار(مقدار سه کانال \lr{RGB} در تصویر اصلی) خواهد بود. 	این روند را برای تمامی پیکسل های ۱۰ تصویر انجام دهید تا برای هر تصویر $i$ یک مجموعه داده به صورت 
	$W_i*H_i, 27, 3$ پدید آید. دو تصویر را برای آزمون، و یک تصویر را برای اعتبار سنجی و هفت تصویر باقی مانده را برای آموزش استفاده کنید. می‌توانید پیکسل های حاصل از تصاویر مختلف در گروه آموزش را باهم ترکیب کرده و درهم (\lr{shuffle}) سازید که ابعاد آن مجموعه داده به صورت $\sum_{i=1}^{7} W_i*H_i, 27, 3$ در‌آید.
	


	
	
	
	
	
	\item یک شبکه چند لایه پرسپترونی طراحی و آموزش دهید که بتواند به ازای ۲۷ ویژگی ورودی در وضوح پایین، مقدار پیکسل رنگی در وضوح بالا را محاسبه کنید. معماری خود را ترسیم نموده و آموزش شبکه را توضیح دهید. از چه تابع خطایی برای آموزش استفاده کرده‌اید؟ موارد ذکر شده در ابتدای پروژه را برای این سوال به‌صورت کامل گزارش دهید و نتایج را تحلیل کنید.
	
	
	
	\item مقدار تابع خطا را به ازای مجموعه داده آزمون مجاسبه و گزارش نمایید و در گام نهایی تصاویر با وضوح بالا را تولید نموده و آن را با تصاویر اصلی مقایسه کنید. علاوه بر مقایسه‌ی بصری، معیار‌های کمی
	\texttt{SSIM} و \texttt{PSNR} را مطالعه کرده و بر اساس آن عملکرد شبکه خود را ارزیابی کنید.

	
	
	
	
	
	\item اگر از شبکه‌ی قسمت ۲، دوبار متوالی استفاده شود، می‌تواند وضوح تصویر را چهار برابر کند. به نظر شما این رویکرد می‌تواند مفید واقع شود یا یک شبکه ای که به صورت مستقیم چهار برابر وضوح را افزایش می‌دهد؟ با انجام آزمایش و گزارش کمی نتیجه مورد نظر را نشان دهید.
	
	

\end{enumerate}










\begin{qsolve}
فایل کد از مسیر \texttt{code/Q1.ipynb} قابل مشاهده است.

دیتاست مورد استفاده در این تمرین، دیتاست \texttt{CIFAR10} است که ۱۰ نمونه از آن به عنوان ورودی شبکه انتخاب شده است.

\begin{center}
	\includegraphics*[width=0.7\linewidth]{pics/img14.png}
	\captionof{figure}{تصاویر اصلی مورد استفاده در این سوال}
	\label{تصاویر اصلی مورد استفاده در این سوال}
\end{center}

سپس طبق صورت سوال وضوح تصاویر را تصف می‌کنیم:

\begin{center}
	\includegraphics*[width=0.7\linewidth]{pics/img15.png}
	\captionof{figure}{تصاویر با وضوح نصف}
	\label{تصاویر با وضوح نصف}
\end{center}
 
\end{qsolve}





\begin{qsolve}
	سپس ویژگی های گفته شده را از تصویر استخراج می‌کنیم. خروجی و ابعاد ویژگی‌های استخراج شده به صورت زیر است:
	
	\begin{latin}
		\texttt{Size of features tensor: torch.Size([10240, 27])}\\
		\texttt{Size of labels tensor: torch.Size([10240, 3])}
	\end{latin}
	همانطور که در صورت سوال نیز گفته شده است ابعاد بردار ویژگی‌ها باید به صورت (۳، ۲۷، ۱۰۲۴) باشد. در ابعاد گزارشی توسط ما عدد ۱۰۲۴ به ۱۰۲۴۰ تبدیل شده است که این به دلیل آن است که ۱۰ عدد تصویر داشتیم. در این کد ما قسمت لیبل را از بردار ویژگی ها جدا کردیم و خود برداری با ابعاد (۳، ۱۰۲۴۰) شده است.
	
	پس از استخراج ویژگی ها، طبق خواسته مسئله داده ها را به سه دسته آموزش، تست و اعتبارسنجی تقسیم می‌کنیم. ابعاد خروجی به صورت زیر می‌شود:
	
	\begin{latin}
		\texttt{Size of training features tensor: torch.Size([7168, 27])} \\
		\texttt{Size of training labels tensor: torch.Size([7168, 3])} \\
		\texttt{Size of testing features tensor: torch.Size([2048, 27])} \\
		\texttt{Size of testing labels tensor: torch.Size([2048, 3])} \\
		\texttt{Size of validation features tensor: torch.Size([1024, 27])} \\
		\texttt{Size of validation labels tensor: torch.Size([1024, 3])} \\
	\end{latin}
	
	پس از استخراج ویژگی ها نوبت به آموزش شبکه می‌رسد. در این مسال شبکه ای با معماری زیر طراحی شده است:
	
	\begin{enumerate}
		\item تعداد لایه ها: ۴ لایه (ورودی + ۲ لایه مخفی + خروجی)
		\item تعداد نرون های ورودی: ۲۷
		\item تعداد نرونهای لایه مخفی اول:‌ ۶۴
		\item تعداد نرون های لایه مخفی دوم: ۱۲۸
		\item تعداد نرون های خروجی: ۳
		\item تابع فعال‌ساز همه لایه ها: \lr{ReLU}
	\end{enumerate}
	
	
\end{qsolve}
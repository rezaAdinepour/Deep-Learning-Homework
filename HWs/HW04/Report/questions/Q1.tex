\section{سوال اول - نظری}

نحوه اشتراک گذاری پارمتر‌ها  در لایه های کانولوشنی باعث ویژگی ‫‪\lr{Equivariance}‬‬ نسبت به ‫‪\lr{Translation}‬‬ می شود. این ویژگی را شرح دهید و کاربرد آن‌را توضیح دهید.



\begin{qsolve}
شبکه‌های \lr{CNN} دارای ویژگی \lr{Equivariance} هستند. یعنی با اعمال تبدیلاتی (مانند جابه‌جایی) در ورودی شبکه، تبدیل‌هایی متناظری را در خروجی ایجاد می‌کند. تاکو کوهن در \cite{ref1} به عنوان‌ اولین نفر این به این موضوع پرداخت.

اگر تعریف کانولوشن به صورت زیر باشد:

	\begin{eqnarray*}
		(f \star \Psi)(x)&=&\sum_{y\in \mathbf{Z^2}}\sum_{k=1}^{K}g_k(y)\Psi_k(y-x)
	\end{eqnarray*}
	
	در اینجا $\Psi$ و $f$ هردو دارای کانال $k$ هستند. که در این مقاله $k=1$ درنظر گرفته شده است.
	
ما در اینجا یک تصویر $f$ داریم که می‌خواهیم آن را با یک کرنل $\Psi$ کانوالو کنیم تا \lr{Feature map} های تصویر را به‌دست آوریم. سپس می‌خواهیم بدانیم که برای هر تبدیل  $t$ آیا دو مورد زیر یکسان است یا خیر:

\begin{enumerate}
	\item تبدیل تصویر $f$ با $t$ و کانولوشن حاصل تبدیل با کرنل $\Psi$ 
	
	\item کانولوشن تصویر $f$ با $\Psi$ و سپس تبدیل حاصل با $t$
\end{enumerate}

بنابر می‌بایست رابطه زیر را اثبات کنیم:
\begin{eqnarray*}
	(L_tf)\star \Psi&=&L_t(f\star \Psi)
\end{eqnarray*}

برای اثبات یک تغیر متغیر به صورت $y\leftarrow x+y$ انجام می‌دهیم و رابطه کانولوشن را بازنویسی می‌کنیم:

\begin{eqnarray*}
	(f \star \Psi)(x)&=&\sum_{y\in \mathbf{Z^2}} f(y)\Psi(y-x)\\
	&=&\sum_{y\in \mathbf{Z^2}} f(x+y)\Psi(y)
\end{eqnarray*}

دو طرف معادله را باتوجه به عبارتی که می‌خواهیم آن را اثبات کنیم بازنویسی می‌کنیم:
\end{qsolve}


\begin{qsolve}
	\begin{eqnarray*}
		((L_tf)\star \Psi)(x)&=&((f\circ t^{-1})\star \Psi)(x)\\
		&=&\sum_{y\in \mathbf{Z^2}} f(t^{-1} (x+y))\Psi(y)\\
		&=&\sum_{y\in \mathbf{Z^2}} f(x+y-t)\Psi(y)
	\end{eqnarray*}
	
	و $L_t(f\star \Psi)$ به صورت زیر تعریف می‌شود:
	\begin{eqnarray*}
		(L_t(f \star \Psi))(x)&=&(f\star \Psi)(x-t)\\
		&=&\sum_{y\in \mathbf{Z^2}} f((x-t)+y)\Psi(y)\\
		&=&\sum_{y\in \mathbf{Z^2}} f(x+y-t)\Psi(y)\\
	\end{eqnarray*}
	
	و مشاهده می‌شود که دو طرف تساوی باهم برابر است.
	
	همچنین از کاربردهای آن می‌توان به موارد زیر اشاره کرد:
	
	\begin{enumerate}
		\item \lr{\textbf{Spatial Consistency}}\\
		تضمین می‌کند که الگوها یا ویژگی‌ها را می‌توان بدون توجه به موقعیت آنها در ورودی تشخیص داد و شبکه عصبی را در برابر تغییرات و \lr{Translation} ها انعطاف‌پذیر می‌کند.
		
		
		\item \textbf{کاهش پیچیدگی}\\
		از آنجایی که پارامتر‌های یکسان در کل فضای ورودی استفاده می‌شود، \lr{CNN} ها پارامتر کمتری در مقایسه با شبکه‌های \lr{Fully connected} با اندازه مشابه دارند.
		
		\item تعمیم یادگیری
	\end{enumerate}
	
	
	
	  سازگاری فضایی: تضمین می‌کند که الگوها یا ویژگی‌ها را می‌توان بدون توجه به موقعیت آنها در ورودی تشخیص داد و شبکه عصبی را در برابر تغییرات و ترجمه‌ها انعطاف‌پذیرتر و قوی‌تر می‌کند.
	کاهش پیچیدگی: از آنجایی که پارامترهای یکسان در کل فضای ورودی استفاده می شود، CNN ها پارامترهای کمتری در مقایسه با شبکه های کاملا متصل با اندازه مشابه دارند. این ویژگی باعث کاهش بیش از حد برازش و پیچیدگی محاسباتی می شود.
	تعمیم یادگیری: CNN ها می توانند بدون نیاز به دانستن موقعیت خاص آنها در ورودی، شناسایی ویژگی ها را بیاموزند و به تعمیم داده های مختلف کمک کنند.
	
	با این حال، شایان ذکر است که در حالی که لایه‌های کانولوشن معادل ترجمه هستند، ذاتاً ثابت نیستند. تغییر ناپذیری را می توان با ادغام لایه ها یا مکانیسم های دیگری که حساسیت به موقعیت مکانی دقیق را کاهش می دهد به دست آورد.
	
	
	
	
	
\end{qsolve}





\begin{latin}
	\begin{thebibliography}{9}
		\bibitem{ref1}
		Cohen T, Welling M. Group equivariant convolutional networks. InInternational conference on machine learning 2016 Jun 11 (pp. 2990-2999). PMLR.
		
	\end{thebibliography} 
\end{latin}














%
%برای آموزش مدل‌های زبانی بزرگ (\lr{Large Language Model}) که حاوی میلیون‌ها و میلیارد‌ها پارامتر هستند، از حجم قابل توجهی داده استفاده می‌شود. اما در تمامی این مدل‌ها یک تاریخ قطع آموزش وجود دارد که مدل زبانی هیچ اطلاعاتی در خصوص داده‌های تولید شده‌ی پس از این زمان ندارد. به‌عنوان مثال، تاریخ قطع آموزش مدل \lr{GPT-3.5-turbu-instruction} سپتامبر ۲۰۲۱ است و از همین رو این مدل ممکن است به سوالات مربوط به رویداد‌های سال ۲۰۲۲، ۲۰۲۳ و ۲۰۲۴ پاسخ صحیح ندهد. چنین داده‌هایی که بعد از تاریخ قطع آموزش تولید شده‌اند و یا بخشی از داده‌ی آموزشی اولیه‌ی مدل زبانی نیستند را داده‌ی خارجی می‌گوییم. تکنیک تولید تقویت شده با بازیابی (\lr{RAG}) رویکردی است که با استخراج داده‌ی خارجی متناسب با فرمان، دریافت شده و افزودن آن به‌عنوان ورودی به مدل زبانی تلاش می‌کند که فرمان ورودی را تقویت کرده و به مدل زبانی کمک می‌کند تا جواب مرتبط و متناسبی بسازد. به‌عنوان مثال در پاسخ به یک فرمان متنی مانند «چه‌کسی شرکت توییتر را درسال ۲۰۲۲ خرید؟» تمامی داده‌های خارجی متناسب با این فرمان را استخراج می‌کند و آن‌ها را به‌عنوان ورودی به مدل زبانی \lr{GPT-3.5-turbo-instruct}
%می‌دهد تا مدل زبانی بتواند با دانش دریافت شده پاسخ متناسبی تولید کند. این رویکرد نیاز به آموزش مجدد و با باز‌تنظیم (\lr{Fine tune})
%مدل زبانی را برطرف می‌سازد. در این پروژه می‌خواهیم با استفاده از شبکه‌های خودسازمان‌ده این تکنیک را پیاده‌سازی کنیم.
%
%\begin{center}
%	\includegraphics*[width=0.8\linewidth]{pics/img1.png}
%	\captionof{figure}{فرآیند کلی RAG در یک مدل زبانی بزرگ}
%	\label{داده‌های تولید شده برای مسئله}
%\end{center}
%
%
%وظیفه اصلی RAG جست‌و‌جو معنایی (\lr{Semantic search}) در پایگاه داه‌های اطلاعاتی و بازیابی اطلاعات خارجی دارای تناسب محتوایی با فرمان داده‌شده به یک مدل زبانی است.برای تسهیل جست‌و‌جوی معنایی، ابتدا داده‌های خارجی استخراج شده به بازنمایی‌های عددی یا برداری تبدیل می‌شوند که به این بازنمایی، تعبیه‌ی متن (\lr{Text embedding}) می‌گوییم. در زمان بازیابی نیز ابتدا فرمان متنی به بازنمایی برداری تبدیل می‌شود و سپس نزدیک‌ترین بردار‌های داده‌ی خارجی متناسب با آن استخراج می‌شود. شکل «\textcolor{blue}{\ref{داده‌های تولید شده برای مسئله}}»
%دیاگرام کلی این فرآیند را نشان می‌دهد. چالش اصلی این رویکرد این است که جست‌و‌جوی معنایی ذکر شده به دلیل نیازمندی به محاسبه‌ی فاصله‌ی بردار فرمان با حجم عظیمی از بردار‌های داده‌ی خارجی، به منابع پردازشی و محاسباتی زیاد و زمان قابل توجهی نیاز دارد. بنابر این پیدا کردن رویکردی که جست‌و‌جوی معنایی را به‌صورت کارا انجام دهد بسیار حائز اهمیت است.
%
%برای افزایش کارایی جست‌و‌جو معنایی، یک رویکرد رایج این است که بردار‌های داده‌های خارجی را خوشه‌بندی کنیم و در زمان جست‌و‌جو نیز ایتدا خوشه مشابه با بردار فرمان ورودی را پیدا می‌کنیم و سپس شباهت بردار‌های داده‌های خارجی متعلق به آن خوشه با بردار فرمان را محاسبه می‌کنیم و اگر شباهت بردار‌ها از یک آستانه بیشتر باشد، آنها را به‌عنوان اطلاعات مرتبط درنظر می‌گیریم.
%
%\begin{enumerate}
%	\item در این پروژه قصد داریم برای خوشه‌بندی داده‌های خارجی از شبکه خود‌سازمان‌ده استفاده کنیم. بررسی کنید که در این شبکه‌ها نسبت به سایر روش‌های خوشه‌بندی که در یادگیری ماشین به‌کار گرفته می‌شود، چه مزایا و معایبی دارد؟ به نظر شما، چرا استفاده از شبکه خودسازمان‌ده به صورت با نظارت صورت نمی‌گیرد؟ فرآیند یادگیری این مدل‌ها را توضیح دهید.
%	
%	\begin{qsolve}
%قبل از بررسی مزایا و معایب شبکه \lr{SOM} نیاز است که یک‌سری پیش‌نیاز ها را توضیح دهیم. پیش از هر چیزی ابتدا می‌بایست انواع الگوریتم های یادگیری ماشین و دلیل استفاده از آنها‌را توضیح دهیم. الگوریتم های یادگیری ماشین به ۳ دسته مختلف تقسیم می‌شوند:
%
%	\begin{enumerate}
%		\item یادگیری با نظارت (\lr{Supervised Learning})
%		\item یادگیری نیمه نظارتی (\lr{Semi-supervised Learning})
%		\item  یادگیری بدون نظارت (\lr{Unsupervised Learning})
%	\end{enumerate}
%در یادگیری بانظارت، داده و لیبل‌های متناظر با آنها را داریم. در یادگیری نیمه نظارتی، صرفا بخشی از داده‌ها لیبل دارند و لیبل بقیه داده‌ها مشخص نیست. دسته آخر که مورد بحث ماست، یادگیری بدون نظارت است که داده‌های موجود، لیبل ندارند و به ازای داده‌های مختلف، خروجی مناسب را نمی‌دانیم و از الگو‌های پنهان در داده‌ها اطلاعی نداریم. در این صورت است که به سمت الگوریتم‌های بدون نظارت می‌آییم تا به الگوریتم این اجازه را بدهیم که هرچه را می‌تواند یاد بگیرد و اطلاعات پنهان در داده‌ها را مشخص کند. الگوریتم‌های خوشه‌بندی در این دسته قرار می‌گیرند و دلیل قرارگیری در این دسته آن است که ما هیچ اطلاعاتی درمورد داده‌های ورودی نداریم و به دنبال ایجاد وابستگی میان آنها هستیم. الگوریتم‌های خوشه‌بندی این امکان را برای ما فراهم می‌سازد تا داده‌های شبیه به هم را در یک دسته قرار دهد. در این باره در صفحه ۱۴۱ \cite{ref1} گفته شده است:
%
%« \textbf{تکنیک‌های خوشه‌بندی زمانی اعمال می‌شوند که کلاسی برای پیش‌بینی وجود نداشته باشد، بلکه زمانی که نمونه‌ها باید به گروه‌های طبیعی تقسیم شوند، اعمال می‌شوند.} »
%	
%	
%پس اگر با داده‌هایی مواجه بودیم که اطلاعاتی در مورد آنها نمی‌دانیم،‌ خوشه‌یابی بهترین روش برای درک وابستگی‌ها میان داده‌هاست. الگوریتم‌های خوشه‌یابی را می‌توان به‌صورت زیر دسته‌بندی کرد:
%
%	\begin{latin}
%		\begin{enumerate}
%			\item Density-based
%			\item Distribution-based
%			\item Centroid-based
%			\item Hierarchical-based
%		\end{enumerate}
%	\end{latin}
%	
%	در الگوریتم‌های خوشه‌یابی مبتنی بر چگالی، داده‌ها بر اساس تراکم و غلظت داده‌ها در نقاط مختلف تقسیم‌بندی می‌شود. 
%	\end{qsolve}
%	
%	
%	
%	\begin{qsolve}
%در خوشه‌یابی توزیع شده، اساس خوشه یابی به‌صورت احتمالی است. یعنی برای تمام نقاط یک احتمال تعلق به یک خوشه خاص درنظر گرفته می‌شود که با دور شدن داده از مرکز آن خوشه، احتمال تعلق داده به خوشه مربوطه کاهش پیدا می‌کند.
%
%پرکاربرد ترین و سریع‌ترین نوع خوشه‌یابی، خوشه‌یابی \lr{Centroid} است. این الگوریتم نقطه‌ها را بر اساس چندین مرکز در داده‌ها جدا می‌کند و هر نقطه بر اساس مجذور فاصله‌اش تا مرکز داده به یک خوشه اختصاص می‌یابد.
%
%استفاده از خوشه‌بندی سلسله‌مراتبی محدود تر از سایر روش هاست. بدین صورت است که برای داده‌هایی که ذاتا به صورت سلسله‌مراتبی هستند استفاده می‌شود. مانند داده‌های مربوط به یک پایگاه داده.
%
%الگوریتم های مختلفی برای خوشه‌یابی وجود دارد که می‌توان چندتا از آنها را به‌صورت زیر نام برد:
%
%	\begin{latin}
%		\begin{enumerate}
%			\item SOM
%			\item K-means
%			\item DBSCAN
%			\item Gaussian Mixture
%			\item BIRCH
%			\item Affinity Propagation
%			\item Mean-Shift
%			\item OPTICS
%		\end{enumerate}
%	\end{latin}
%	
%	در این سوال به بررسی دو مورد از مهم‌ترین الگوریتم ها یعنی \lr{SOM} و \lr{K-means} می‌پردازیم.
%	
%	\begin{enumerate}
%		\item \lr{\textbf{:K-Means}}
%		الگوریتم \lr{K-Means} یک الگوریتم بدون نظارت، مبتنی بر مرکز و تکراری (\lr{iterative}) است که داده های ورودی را دریافت می‌کند و آنها را به \lr{K} دسته تقسیم می‌کند. مقدار \lr{K} می‌بایست از قبل مشخص باشد. هدف در الگوریتم \lr{K-Means} به حداقل رساندن مجموع فواصل بین دو نقطه داده شده و خوشه مربوط به آنهاست و تا زمانی که مینیمم فاصله را پیدا نکند، الگوریتم متوقف نمی‌شود.
%		
%		\textbf{ذکر این نکته الزامی است که در این الگوریتم، آموزشی‌ای صورت نمی‌گیرد و صرفا یک کار تکراری چندین بار تکرار می‌شود تا زمانی که بهینه‌ترین حالت پیدا شود.}
%		
%		شکل «\ref{ساختار الگوریتم K-Means}» نحوه عملکرد الگوریتم \lr{K-Means} را نشان می‌دهد.
%	
%	
%	\begin{center}
%		\includegraphics*[width=0.7\linewidth]{pics/img2.png}
%		\captionof{figure}{ساختار الگوریتم \lr{K-Means}}
%		\label{ساختار الگوریتم K-Means}
%	\end{center}
%	
%	
%	\end{enumerate}
%	
%\end{qsolve}
%	
%	
%	
%\begin{qsolve}
%مراحل انجام الگوریتم \lr{K-Means} به‌صورت زیر است:
%
%\begin{enumerate}
%	\item \textbf{مرحله ۱: } انتخاب مقدار \lr{K} بر اساس تعداد خوشه‌ها. اگر تعداد خوشه‌ها را نمی‌دانیم، عددی بزرگ را انتخاب می‌کنیم.
%	
%	\item \textbf{مرحله ۲:} انتخاب \lr{K} نقطه به‌صورت رندم و تصادفی.
%	
%	\item \textbf{مرحله ۳:} قرار دادن هر نقطه در نزدیک‌ترین مرکز آن. (مرکز \lr{K} خوشه‌ای که از قبل تعیین شده است.)
%	
%	\item \textbf{مرحله ۴:} واریناس را حساب کرده و مرکز جدید را برحسب واریانس انتخاب کرده
%	
%	\item \textbf{مرحله ۵:} تکرار مرحله ۳. یعنی قرار دادن هر نقطه در مرکز جدید تعیین شده
%	
%	\item \textbf{مرحله ۶:} اگر هر تخصیص مجددی رخ داد به مرحله ۴ باید برویم درغیر این صورت به مرحله ۷
%	
%	\item \textbf{مرحله ۷:} پایان الگوریتم
%\end{enumerate}
%
%برای درک بهتر، در ادامه با رسم شکل مراحل بالا را توضیح خواهیم داد. فرض شود که داده‌های ورودی ما به‌صورت زیر باشد:
%
%\begin{center}
%	\includegraphics*[width=0.5\linewidth]{pics/img3.png}
%	\captionof{figure}{داده‌های ورودی}
%	\label{داده‌های ورودی}
%\end{center}
%
%در اینجا چون تعداد خوشه‌ها برای ما مشخص است، مقدار \lr{K} را ۲ فرض می‌کنیم. و دو نقطه به‌صورت رندم در صفحه به‌عنوان نقاط شروع الگوریتم انتخاب می‌کنیم. شکل «\ref{نقاط ابتدایی الگوریتم}»
%
%\end{qsolve}
%	
%	
%	
%	
%	
%\begin{qsolve}
%	\begin{center}
%		\includegraphics*[width=0.5\linewidth]{pics/img4.png}
%		\captionof{figure}{نقاط ابتدایی الگوریتم}
%		\label{نقاط ابتدایی الگوریتم}
%	\end{center}
%	
%	
%	اکنون هر نقطه را به نزدیک‌ترین مرکز اختصاص می‌دهیم. این عملیات با محاسبه فاصله بین نقطه‌ها انجام می‌شود. سپس به مرحله آپدیت مرکز می‌رویم و برحسب واریانس محاسبه کرده، مرکز نقاط را آپدیت می‌کنیم. شکل «\ref{آپدیت مراکز}»
%	
%	
%	 \begin{center}
%	 	\includegraphics*[width=0.5\linewidth]{pics/img5.png}
%	 	\captionof{figure}{آپدیت مراکز}
%	 	\label{آپدیت مراکز}
%	 \end{center}
%
%	این فرآیند را آنقدر ادامه می‌دهیم تا مینیمم ترین فاصله نقاط از مراکز به‌دست آید و داده‌ها خوشه‌بندی شود. شکل «\ref{داده‌های خوشه‌بندی شده}»
%
%\end{qsolve}
%	
%	
%	
%	
%	
%\begin{qsolve}
%	\begin{center}
%		\includegraphics*[width=0.5\linewidth]{pics/img6.png}
%		\captionof{figure}{داده‌های خوشه‌بندی شده}
%		\label{داده‌های خوشه‌بندی شده}
%	\end{center}
%	
%	
%	
%	\begin{enumerate}
%		\item \textbf{\lr{:SOM}}
%		\lr{SOM} بر خلاف \lr{K-Means} یک شبکه عصبی است که بر اساس یادگیری بدون نظارت کار می‌کند. شبکه \lr{SOM} کاربرد‌های مختلفی دارد. کاربرد اصلی شبکه \lr{SOM} نگاشت داده‌های با بعد بالا به داده‌هایی با بعد پایین است. اما از این شبکه برای خوشه‌یابی نیز استفاده می‌شود
%		شبکه \lr{SOM} تنها از دو لایه تشکیل می‌شود. (لایه ورودی + خروجی) که لایه خروجی می‌تواند به صورت پشت سر هم و یا در یک ساختار شبکه ای قرار گیرند. شکل «\ref{ساختار شبکه SOM}»
%		
%		\begin{center}
%			\includegraphics*[width=0.8\linewidth]{pics/img7.png}
%			\captionof{figure}{ساختار شبکه \lr{SOM}}
%			\label{ساختار شبکه SOM}
%		\end{center}
%	
%	در فرآیند آموزش وزن‌های متصل از ورودی به خروجی آموزش داده می‌شوند و در نهایت، هر نورون نماینده یک دسته (خوشه) از داده‌های ورودی است. الگوریتم یادگیری در \lr{SOM}، رقابتی (\lr{Competitive}) است. یعنی نورون‌های خروجی باهم بر سر نماینده شدن برای داده‌های ورودی رقابت می‌کنند و نورون برنده وزنش به نسبت نورون بازنده بیشتر اصلاح می‌شود. در \lr{SOM} نیز همانند \lr{K-Means} اگر تعداد خوشه‌ها را از قبل نمی‌دانستیم می‌بایست عدد بزرگی را برای آن درنظر بگیریم. \cite{ref2}
%	
%	الگوریتم رقابتی در \lr{SOM} را می‌ةوان به دو صورت انجام داد.
%	
%	\begin{enumerate}
%		\item ارسال سیگنال به نورون‌های دیگر
%		\item محاسبه فاصله تا ورودی
%	\end{enumerate}
%	
%	معمولا در تمامی شبکه‌های \lr{SOM} متداول است که از روش دوم استفاده شود اما در ادامه توضیح هر دو روش را خواهیم داد.	
%	\end{enumerate}
%\end{qsolve}
%
%
%
%
%\begin{qsolve}
%برای روش اول داریم:
%
%ابتدا می‌بایست هر نرون خروجی‌اش را به صورت زیر تولید کند:
%
% $$ u_j=\sum_{i-1}^{n} w_{ij}x_i $$
% 
% پس از محاسبه $u_j$ هر نورون خروجی $u_j$ خودش را با علامت معکوس به تمامی نورون‌های دیگر می‌فرستد. نورون‌ها پس از دریافت سایر $u_j$ ها، می‌بایست مقادیر $u_j$ های خودشان را با سایر $u_j$ های وارد شده جمع کنند. حالا اگر مقدار حاصل از یک آستانه کمتر شود، (مثلا صفر) نورون مربوطه از رقابت خارج می‌شود. این فرآیند تا زمانی ادامه پیدا خواهد کرد که فقط یک نورون باقی بماند و آن نورون به عنوان نورون برنده مشخص می‌شود.
% 
% 
% همانطور که گفته شد معمولا از این روش استفاده نمی‌شود و از روش دوم استفاده می‌شود. یعنی محاسبه فاصله تا ورودی. در این روش فاصله بردار ورودی طبق یکی از روابط تعیین فاصله (در اینجا فاصله اقلیدسی) برای تمامی وزن‌ها محاسبه می‌شود و نورونی که کمترین فاصله با بردار ورودی را داشته باشد به‌عنوان نورون برنده مشخص می‌شود.
% 
% $$ d_j=x-w_j=\sqrt{\sum_{i=1}^{n} (x_i-w_{ij})^2} $$
% 
% پس از محاسبه همه فاصله‌ها، مقدار وزن نورون برنده به‌صورت زیر آپدیت می‌شود:
% 
% $$ \Delta w_j=\beta(x-w_j)=\beta d_j$$
% 
% در نهایت، پس از همگراشدن شبکه، داده‌ها همگی در خوشه‌های مربوط به خودشان قرار می‌گیرند. شکل«»
% 
% \begin{center}
% 	\includegraphics*[width=0.8\linewidth]{pics/img8.png}
% 	\captionof{figure}{داده‌های خوشه‌بندی شده شبکه \lr{SOM} پس از آموزش}
% 	\label{داده‌های خوشه‌بندی شده شبکه SOM پس از آموزش}
% \end{center}
% 
% 
% از مزایا و معایب این دو الگوریتم می‌توان به موارد زیر اشاره کرد:
%
%\end{qsolve}
%
%
%
%
%\begin{qsolve}
%	\begin{enumerate}
%		\item \textbf{:K-Means}
%		\begin{enumerate}
%			\item مزایا: 
%			\begin{itemize}
%				\item الگوریتم \lr{K-Means} نسبت به شبکه \lr{SOM} از سرعت بالا تری برخوردار است. دلیل این افزایش سرعت، سادگی پیاده‌سازی آن به نسبت \lr{SOM} است.
%				
%				\item بر روی داده‌های بزرگ به‌خوبی کار می کند
%			\end{itemize}
%			
%			
%			\item معایب:
%			\begin{itemize}
%				\item کاملا وابسته و حساس به مقدار‌دهی اولیه برای نقاط مربوط به \lr{K} هاست.
%				
%				\item برای خوشه‌یابی داده‌هایی که ساختار غیر محدب دارند، نامناسب است.
%				
%				\item وابستگی شبکه به مشخص کردن تعداد خوشه‌ها پیش از اجرای الگوریتم
%			\end{itemize}
%		\end{enumerate}
%		
%		
%		
%		
%		
%		
%		
%		
%		\item \textbf{:SOM}
%		\begin{enumerate}
%			\item مزایا:
%			\begin{itemize}
%				\item کاربردهای گسترده به جز خوشه‌یابی
%				\item بدست آوردن روابط پیچیده میان داده‌ها
%			\end{itemize}
%			
%			
%			
%			
%			\item معایب:
%			\begin{itemize}
%				\item بار محاسباتی بیشتر و سرعت کمتر نسبت به الگوریتم \lr{K-Means} 
%				
%				\item وابسته بودن شبکه به پارامتر‌های مختلف ورودی مثل نرخ یادگیری، سایز همسایگی و ...
%			\end{itemize}
%		\end{enumerate}
%	\end{enumerate}
%	
%	
%\end{qsolve}
%
%
%
%\begin{latin}
%	\begin{thebibliography}{9}
%		\bibitem{ref1}
%		Data Mining: Practical Machine Learning Tools and Techniques, 2016.
%		
%		\bibitem{ref2}
%		Neural Networks for Applied Sciences and Engineering, 2006 by Taylor \& Francis Group, LLC
%		
%		
%		\bibitem{ref3}
%		Frey BJ, Dueck D. Clustering by passing messages between data points. science. 2007 Feb 16;315(5814):972-6.
%		
%		\bibitem{ref4}
%		Sculley D. Web-scale k-means clustering. InProceedings of the 19th international conference on World wide web 2010 Apr 26 (pp. 1177-1178).
%		
%		\bibitem{ref5}
%		MacQueen J. Some methods for classification and analysis of multivariate observations. InProceedings of the fifth Berkeley symposium on mathematical statistics and probability 1967 Jun 21 (Vol. 1, No. 14, pp. 281-297).
%		
%		
%		\bibitem{ref6}
%		Comaniciu D, Meer P. Mean shift: A robust approach toward feature space analysis. IEEE Transactions on pattern analysis and machine intelligence. 2002 May;24(5):603-19.
%		
%		\bibitem{ref7}
%		Ng A, Jordan M, Weiss Y. On spectral clustering: Analysis and an algorithm. Advances in neural information processing systems. 2001;14.
%		
%	\end{thebibliography} 
%\end{latin}
%	
%	
%	\newpage
%	
%	
%	
%	\item مجموعه داده ارائه شده در این پروژه شامل رویداد‌های سه‌سال متوالی از ۲۰۲۲ تا ۲۰۲۴ است که از سایت ویکی‌پدیا جمع‌آوری شده است. داده‌ی مربوطه را بارگزاری کنید و پیش‌پردازش‌های متنی شامل حذف کلمات ایست (\lr{Stop word})، واحدسازی کلمات (‫‪Tokenization‬‬) و تبدیل به بردار‌های \lr{GloVe} را روی آ
%	ن انجام دهید.
%	
%	
%	
%	\begin{qsolve}
%		فایل کد در مسیر \texttt{Code/Q1-P3.ipynb} موجود است. ابتدا کتابخانه‌های مورد نیاز برای کار با متن را نصب می‌کنیم، کتابخانه‌هایی مانند:
%		
%		\begin{latin}
%			\begin{enumerate}
%				\item \texttt{nltk}
%				\item \texttt{textblob}
%				\item \texttt{minisom}
%			\end{enumerate}
%		\end{latin}
%	
%	
%	پس از نصب کتابخانه‌ها، دیتاست موجود (فایل \texttt{WikipediaEvents.csv}) را می‌خوانیم. ایعاد این دیتاست \texttt{1, 473} است.
%	
%	 \begin{center}
%		\includegraphics*[width=0.7\linewidth]{pics/img9.png}
%		\captionof{figure}{دیتاست ورودی}
%		\label{دیتاست ورودی}
%	\end{center}
%	
%	در ادامه، عملیات \lr{Pre-processing} شامل کوچک کوچک کردن تمامی حروف، حذف علائم نگارشی، اعداد و کاراکترهای \lr{newline} را حذف می‌کنیم. این عملیات‌ها در تابع \texttt{clean\_text} نوشته شده است. پس از اعمال تابع نام‌برده بر روی دیتاست موجود، همه متن به حروف کوچک تبدیل می‌شود، تاریخ تمامی سال‌ها حذف می‌شود و فقط ماه‌ مورد نظر باقی می‌ماند، همچنین کاراکتر‌های اضافی مانند \texttt{-} و \texttt{,} نیز حذف شده است. دیتاست پس از انجام این مراحل به صورت زیر می‌شود:
%	
%	\begin{center}
%		\includegraphics*[width=0.7\linewidth]{pics/img10.png}
%		\captionof{figure}{دیتاست ورودی پس از حذف علائم نگارشی و کوچک سازی کلمات}
%		\label{دیتاست ورودی پس از حذف علائم نگارشی و کوچک سازی کلمات}
%	\end{center}
%	
%	
%	\end{qsolve}
%	
%	
%	
%	
%	
%	
%	
%	\begin{qsolve}
%		برای پیدا کردن کلمات ایست، در دیتاست، از ماژول \texttt{stopwords} استفاده می‌کنیم. کلمات پرتکرار پیدا شده در این دیتاست به‌صورت زیر است:
%		
%		
%		\begin{center}
%			\includegraphics*[width=1\linewidth]{pics/img11.png}
%			\captionof{figure}{کلمات ایست}
%			\label{کلمات ایست}
%		\end{center}
%		
%		
%		
%		
%		همچنین پس از پیدا کردن کلمات، برای حذف آنها تابع \texttt{remove\_stopwords} را نوشته‌ایم. پس از حذف، خروجی به صورت زیر می‌شود:
%		
%		\begin{center}
%			\includegraphics*[width=0.8\linewidth]{pics/img12.png}
%			\captionof{figure}{خروجی پس از حذف کلمات ایست}
%			\label{خروجی پس از حذف کلمات ایست}
%		\end{center}
%		
%		پس از این مرحله، نوبت به \texttt{Tokenization} می‌رسد. برای انجام آن از ماژول \texttt{punkt} استفاده می‌کنیم. پس از انجام \texttt{Tokenization} خروجی به‌صورت زیر می‌شود:
%		
%		\begin{center}
%			\includegraphics*[width=0.8\linewidth]{pics/img13.png}
%			\captionof{figure}{خروجی عملیات \lr{Tokenization}}
%			\label{خروجی عملیات Tokenization}
%		\end{center}
%	
%	
%	پس از \texttt{Tokenization} می‌بایست تبدیل کلمات به بردار را انجام دهیم. برای انجام این کار، از مدل از‌پیش آموزش داده شده \texttt{GloVe} استفاده می‌کنیم. این مدل را می‌توان از \href{https://github.com/allenai/spv2/tree/master/model}{\textcolor{magenta}{اینجا}} دانلود کنید. پس از \lr{fine-tune} کردن مدل، از تابع نوشته شده \texttt{convert\_to\_vector} برای تبدیل کلمات به بردار استفاده می‌کنیم.
%	\end{qsolve}
%	
%	
%	
%	
%	
%	
%	
%	
%	\begin{qsolve}
%		خروجی‌های \lr{Vectorizrd} شده را در فایلی با نام \texttt{word2vec\_out.csv} ذخیره می‌کنیم و خروجی آن به صورت زیر می‌شود:
%		
%		
%		\begin{center}
%			\includegraphics*[width=0.8\linewidth]{pics/img14.png}
%			\captionof{figure}{کلمات تبدیل شده به بردار}
%			\label{کلمات تبدیل شده به بردار}
%		\end{center}
%		
%در مرحله بعد، کلماتی که به بردار تبدیل کرده‌ایم را رسم می‌کنیم. ابعاد بردار‌های بدست آمده (۷۴۶۵،۱۰۰) است. می‌بایست بعد آن را کاهش دهیم تا بتوانیم آن را نمایش دهیم. برای کاهش بعد از ماژول \texttt{TSNE} استفاده کرده‌ایم. ابعاد بردار را به (۷۴۶۵،۲) کاهش می‌دهیم و آن را رسم می‌کنیم. خروجی آن به‌صورت زیر می‌شود:
%
%
%	\begin{center}
%		\includegraphics*[width=0.8\linewidth]{pics/img15.png}
%		\captionof{figure}{نمایش بردارهای کلمات}
%		\label{نمایش بردارهای کلمات}
%	\end{center}
%		
%		
%	\end{qsolve}
%	
%	
%	
%	
%	
%	 \begin{qsolve}
%	 	به دلیل آنکه تعداد کلمات زیاد است و اسامی آن‌ها بر روی آن نوشته شده است و تصویر را شلوغ کرده است، لیبل‌ها را بر روی آن بر می‌داریم و دوباره آن را رسم می‌کنیم:
%	 	
%	 	\begin{center}
%	 		\includegraphics*[width=0.8\linewidth]{pics/img16.png}
%	 		\captionof{figure}{نمایش برداری کلمات بدون اسامی}
%	 		\label{نمایش برداری کلمات بدون اسامی}
%	 	\end{center}
%	 	
%	 	
%	\end{qsolve}
%	 	
%	 	
%	 	
%	 	
%	 	\item پارامتر‌های ورودی مدل \texttt{minisom} را توضیح دهید. پپارامترای شبکه خودسازمان‌ده خود را تنظیم کنید و شبکه را بر روی داده‌های مربوطه آموزش دهید. (مقادیر تمامی پارامتر‌ها را در گزارش خود اضافه کنید.) سپس به‌ازای هر داده‌ی ورودی واحد، منطبق (\lr{Best matching unit}) با آن را به‌دست آورید و به‌عنوان نمایه‌ی داده‌ی مربوطه ذخیره کنید.
%	 	
%	 	
%	 \begin{qsolve}
%	 	برای آموزش شبکه از کلاس \texttt{MiniSom} استفاده می‌کنیم. ورودی‌های این کلاس و مقادیر اولیه آن‌ها به صورت زیر هستند:
%	 	
%	 	\begin{latin}
%	 		\texttt{\_\_init\_\_(self, x, y, input\_len, sigma=1.0, learning\_rate=0.5,}\\
%	 		\texttt{decay\_function=asymptotic\_decay, neighborhood\_function='gaussian'}\\
%	 		\texttt{topology='rectangular', activation\_distance='euclidean', random\_seed=None)}
%	 	\end{latin}
%	 	
%	 	در ادامه به توضیح هر پارامتر می‌پردازیم.
%	 \end{qsolve}
%	 	
%	 	
%	 	
%	 	
%	 	
%	 	
%	 	
%	 	
%	 	
%	 \begin{qsolve}
%	 	
%	 	\begin{enumerate}
%	 		\item \lr{\texttt{x, y = (2, 3)}}
%	 	
%	 		\lr{\texttt{x, y}} ابعاد نورون‌های خروجی را مشخص می‌کند. مثلا اگر مقدار آن را به‌ترتیب ۱ و ۵ قرار دهیم بدین‌معناست که نرون‌های خروجی در ساختار پشت‌سر‌هم  در یک ساختار ۱ بعدی قرار می‌گیرند و ۵ نورون در خروجی شبکه داریم. پس در نتیجه ۵ خوشه داریم.
%	 		
%در این مسئله چون از تعداد خوشه‌ها اطلاعی نداریم مقدار آن را (۲،۳) درنظر گرفتیم. یعنی ساختار نورون‌های خروجی ۲ بعدی است و ۶ نورون (کلاس) در خروجی شبکه داریم.
%	 		
%	 		
%	 		
%	 		\item \lr{\texttt{input\_len=vectors\_2d.shape[1]}}
%	 		
%پارامتر \texttt{input\_len} طول (بعد) داده‌های ورودی شبکه‌را مشخص می‌کند و چون در مسئله ما داده‌ها ۲ بعدی هستند، پس این پارامتر را برابر با \texttt{vectors\_2d.shape[1]} یعنی مقدار ۲ قرار می‌دهیم.
%			
%			
%			
%			
%			\item{\lr{\texttt{sigma=0.5}}}
%
%پارامتر بعدی \texttt{sigma} است. این پارامتر، به نوعی نماینده انحراف معیار است و شعاع همسایگی را مشخص می‌کند. برای مثال در تکرار $t$ مقدار
%$\sigma (t)$ به صورت زیر محاسبه می‌شود:
%
%$$ \sigma (t)= \frac{\sigma}{1+\frac{t}{T}}, \qquad T=\frac{\text{\lr{number of iteration}}}{2}$$
%
%
%هر چقدر مقدار این پارامتر را کوچکتر بگیریم، دقت خوشه‌بندی بالاتر می‌رود و خطای آموزش کمتر می‌شود. مقدار پیش‌فرض این پارامتر، ۱ است که ما در این مسئله آن را ۰٫۵ درنظر گرفتیم.
%
%
%
%			\item{\lr{\texttt{learning\_rate=0.1}}}
%
% پارامتر \texttt{learning\_rate} نرخ یادگیری شبکه را مشخص می‌کند. این ضریب در اصلاح وزن نورون برنده شده خودش را نشان می‌دهد (در سوال اول به‌طور کامل توضیح داده شد). هر چقدر مقدار این پارامتر بزرگ باشد، شبکه ممکن است دچار ناپایداری شود. رنج نرمال این پارامتر در بازه ای بین ۰٫۰۱ تا ۰٫۱ قرار دارد. در این کلاس به طور پیش‌فرض مقدار نرخ‌یادگیری ۰٫۵ فرض شده است اما ما در این مثال مقدار آن را ۰٫۱ قرار دادیم.
% 
% 
% 
% 
% 			\item{\lr{\texttt{decay\_function=asymptotic\_decay}}}
% 			
% 			این پارامتر، مقدار $\sigma$ و \texttt{learning\_rate} را در هر دوره کاهش می‌دهد. مقدار پیش فرض آن بر روی تابع \texttt{asymptotic\_decay} تنظیم شده است. این تابع به‌صورت زیر نوشته شده است:
% 			
% 			\begin{latin}
% 				\texttt{def asymptotic\_decay(learning\_rate, t, max\_iter):}\\
% 				\qquad \texttt{return learning\_rate / (1+t/(max\_iter/2))}
% 			\end{latin}
%	 		
%	 		ورودی‌های آن \texttt{learning\_rate} و ماکزیمم تکرار (\texttt{max\_iter}) است.
%	 		
%	 		
%	 		
%	 		
%	 		\item{\lr{\texttt{neighborhood\_function="gaussian"}}}
%	 		
%	 		این پارامتر، تابع همسایگی نام دارد، وظیفه آن نگاشت وزن ها تحت این توابع است. به صورت پیش‌فرض بر روی تابع \texttt{gaussian} تنظیم شده است اما می‌توان توابع \texttt{mexican\_hat}، \texttt{bubble} و \texttt{triangle} را نیز انتخاب کرد.
%	 		
%	 	\end{enumerate}
%	\end{qsolve}
%	
%	
%	
%	
%	
%	\begin{qsolve}
%		
%	\begin{enumerate}
%		\item{\lr{\texttt{topology="rectangular"}}}
%		
%		این پارامتر نوع توپولوژی نقشه را مشخص می‌کند، دو گزینه دارد که می‌توان انتخاب کرد. \texttt{hexagonal} و \texttt{rectangular} که به‌صورت پیش‌فرض بر روی \texttt{rectangular} تنظیم شده است.
%	
%	
%	
%		
%		\item{\lr{\texttt{activation\_distance="euclidean"}}}
%		این پارامتر تابع فاصله‌ای است که برای فعال شدن نقشه‌ها استفاده می‌شود مقدار پیش‌فرض آن بر روی \texttt{euclidean} تنظیم شده است اما می‌توان توابع \texttt{cosine}، \texttt{manhattan} و \texttt{chebyshev} را انتخاب کرد.
%		
%		
%		
%		
%		\item{\lr{\texttt{random\_seed=10}}}
%		
%		این پارامتر رندوم بودن ورودی شبکه را تعیین می‌کند که به صورت پیش‌فرض بر روی \texttt{None} قرار دارد.
%	\end{enumerate}
%	
%	
%		
%		پس از معرفی پارامتر‌های ورودی شبکه، با استفاده از کلاس \texttt{minisom} شبکه را در ۵۰۰۰۰ دوره آموزش می‌دهیم و خوشه‌های مناسب را پیدا می‌کنیم. این عملیات را برای ۵۰ داده رندوم از میان مجموعه داده‌ها مجددا تکرار می‌کنیم و نتایج آن را گزارش می‌دهیم.
%		
%		
%		به ازای آموزش شبکه با همه داده‌ها در ۵۰۰۰۰ دوره آموزشی و با ۶ نرون دو بعدی در خروجی مقدار خطای شبکه به صورت زیر بدست آمده است:
%		
%		\begin{center}
%			\includegraphics*[width=0.7\linewidth]{pics/img17.png}
%			\captionof{figure}{خطای شبکه}
%			\label{خطای شبکه}
%		\end{center}
%		
%		خروجی شبکه پس از آموزش به‌صورت زیر به‌دست می‌آید:
%		
%		
%		
%		
%		\begin{center}
%			\includegraphics*[width=0.6\linewidth]{pics/img18.png}
%			\captionof{figure}{داده‌های خوشه‌بندی شده پس از آموزش}
%			\label{داده‌های خوشه‌بندی شده پس از آموزش}
%		\end{center}
%		
%	\end{qsolve}
%	
%	
%	
%	
%	
%	
%	
%	
%	\item برای ۵۰ رویداد که به‌صورت تصادفی از مجموعه داده انتخاب شده‌اند، نقشه خروجی را رسم کنید. نقشه‌ی به‌دست آمده را تفسیر کنید.
%	
%	\begin{qsolve}
%		
%		ابتدا ۵۰ رویداد تصادفی را انتخاب و آن را رسم می‌کنیم:
%		
%		\begin{center}
%			\includegraphics*[width=0.8\linewidth]{pics/img20.png}
%			\captionof{figure}{داده‌های رندوم انتخاب شده}
%			\label{داده‌های رندوم انتخاب شده}
%		\end{center}
%		
%		سپس شبکه را با داده‌های جدید (رندم) با همان پارامتر‌های قبل آموزش می‌دهیم. خروجی شبکه به صورت زیر می‌شود:
%		
%		\begin{center}
%			\includegraphics*[width=0.6\linewidth]{pics/img22.png}
%			\captionof{figure}{داده‌های رندوم خوشه‌بندی شده}
%			\label{داده‌های رندوم خوشه‌بندی شده}
%		\end{center}
%	
%	\end{qsolve}
%	
%	
%	
%	\begin{qsolve}
%		خطای آموزش نیز برای داده‌های رندوم به‌صورت زیر به‌دست می‌آید:
%		\begin{center}
%			\includegraphics*[width=0.6\linewidth]{pics/img19.png}
%			\captionof{figure}{خطای آموزش}
%			\label{خطای آموزش برای داده‌های رندوم}
%		\end{center}
%		
%	\end{qsolve}
%	
%	
%	
%	\item فرآیند جست‌و‌جو را به‌صورت زیر برای سه رویداد دلخواه از سه‌سال گذشته انجام دهید. (می‌توانید از پرسش‌های موجود درفایل \texttt{sample\_questions.txt} کمک بگیرید.) و خروجی مربوطه را در گزارش خود اضافه کنید.
%	
%	\begin{itemize}
%		\item تبدیل پرسش به بردار
%		\item پیداکردن نمایه‌ی متناسب با پرسش مربوطه
%		\item پیدا کردن تمامی داده‌های خارجی نمایه‌ی مورد نظر
%		\item محاسبه معیار شباهت کسینوسی و خروجی دادن بردار‌های داده‌های خارجی با شباهت بیشتر از آستانه. (چرا معیار کسینوسی در این مسئله انتخاب مناسبی است؟)
%	\end{itemize}
%	
%	
%	
%	
%	
%	
%	\begin{qsolve}
%		در این قسمت ۱۴ سوال به‌صورت نمونه به ما داده شده است:
%		
%		\begin{latin}
%			\texttt{Who won the 2022 soccer world cup?}\\
%			\texttt{When did Sweden join NATO?}\\
%			\texttt{Who joined NATO in 2023?}\\
%			\texttt{Who joined NATO in 2024?}\\
%			\texttt{Which is the 31st member of NATO?}\\
%			\texttt{Which is the 32nd member of NATO?}\\
%			\texttt{Who won the Cricket World Cup in 2023?}\\
%			\texttt{Who defeated India in Cricket World Cup final in 2023?}\\
%			\texttt{Name the former prime minister of Japan that was assassinated in 2022?}\\
%			\texttt{When did Chandrayaan-3 land near the south pole of the Moon?}\\
%			\texttt{Where did Chandrayaan-3 land on the Moon?}\\
%			\texttt{Who acquired Twitter in 2022?}\\
%			\texttt{Who owns Twitter?}\\
%			\texttt{Who acquired Activision Blizzard in 2023?}
%		\end{latin}
%		
%		
%		در این قسمت در ابدا مشابه با قبل پرسش‌های داده شده را به بردار‌های \texttt{GloVe} تبدیل کرده و مجددا خوشه‌یابی را انجام می‌دهیم. بردار‌های تبدیل شده را در فایلی با نام \texttt{sample\_questions\_vector.csv} ذخیره می‌کنیم.
%	
%	
%	خروجی این تبدیل به‌صورت زیر می‌شود
%	\end{qsolve}
%	
%	
%	
%	
%	\begin{qsolve}
%		\begin{center}
%			\includegraphics*[width=0.6\linewidth]{pics/img23.png}
%			\captionof{figure}{تبدیل سوالات به بردار}
%			\label{تبدیل سوالات به بردار}
%		\end{center}
%		
%		نمایش ۲بعدی بردار‌ها به‌صورت زیر می‌شود:
%		
%		\begin{center}
%			\includegraphics*[width=0.8\linewidth]{pics/img24.png}
%			\captionof{figure}{نمایش ۲بعدی بردار‌های سوال}
%			\label{نمایش ۲بعدی بردار‌های سوال}
%		\end{center}
%	\end{qsolve}
%	
%	
%	
%	\begin{qsolve}
%		خروجی خوشه‌بندی شده به‌صورت زیر می‌شود:
%		\begin{center}
%			\includegraphics*[width=0.6\linewidth]{pics/img25.png}
%			\captionof{figure}{سوالات خوشه‌بندی شده}
%			\label{سوالات خوشه‌بندی شده}
%		\end{center}
%		
%		
%		سپس به سراغ معیار شباهت کسینوسی می‌رویم. معیار شباهت کینوسی، معیاریست برای بررسی شباهت میان دو بردار غیر صفر بر اساس کسینوس زاویه بین آنها که درنتیجه مقداری بین ۱− و ۱ بدست می‌آید. مقدار ۱− دوبردار متعامد و مقدار ۱ دو بردار مشابه را نشان می‌دهد.
%		
%		\begin{center}
%			\includegraphics*[width=1\linewidth]{pics/img21.png}
%			\captionof{figure}{معیار شباهت کسینوسی}
%			\label{معیار شباهت کسینوسی}
%		\end{center}
%		
%	شباهت کسینوسی بین دو بردار به صورت زیر تعریف می‌شود:
%	
%	\begin{eqnarray*}		
%		\text{\lr{similarity(A, B)}}&=&cos(\theta)=\frac{A.B}{\lVert A \rVert \lVert B \rVert}=\frac{\sum_{i=1}^{n}A_iB_i}{\sqrt{\sum_{i=1}^{n}A_i^2 \sum_{i=1}^{n}B_i^2}}
%	\end{eqnarray*}
%	
%	برای بدست آوردن شباهت، از \texttt{cosine\_similarity} کتابخانه \texttt{sklearn} استفاده کردیم. ابعاد بردار شباهت خروجی، \lr{(7465, 126)} شده است که مقدار بیشترین شباهت \lr{0.78742} و کمترین شباهت، \lr{-0.50964} شده است.
%	\end{qsolve}
%	
%	
%	
%	\begin{qsolve}
%	\begin{center}
%		\includegraphics*[width=0.6\linewidth]{pics/img26.png}
%		\captionof{figure}{خروجی شباهت}
%		\label{خروجی شباهت}
%	\end{center}
%	\end{qsolve}
%	
%	
%	
%	
%\end{enumerate}
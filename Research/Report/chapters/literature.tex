
\فصل{کارهای پیشین}\label{کارهای پیشین}
ترنسفورمرها به عنوان جایگزینی برای معماری‌های خاص حوزه‌ها در زمینه‌های مختلفی از جمله زبان، بینایی، یادگیری تقویتی و فراگیری متا معرفی شده‌اند. این مدل‌ها نشان داده‌اند که با افزایش اندازه مدل، توان محاسباتی و داده‌های آموزشی مقیاس‌پذیری قابل توجهی دارند. در خارج از حوزه زبان، ترنسفورمرها برای پیش‌بینی خودرگرسیو پیکسل‌ها و کدبوک‌های گسسته آموزش داده شده‌اند و در مدل‌های تولیدی ماسک شده نیز به کار رفته‌اند. همچنین در مدل‌های انتشار نویززدایی (DDPM) برای تولید داده‌های غیرمکانی مانند تولید جاسازی‌های تصویر CLIP در DALL·E 2 استفاده شده‌اند. در این مقاله، خواص مقیاس‌پذیری ترنسفورمرها را هنگامی که به عنوان ستون فقرات مدل‌های انتشار تصویر استفاده می‌شوند، بررسی می‌کنیم.

مدل‌های انتشار نویززدایی احتمالاتی (DDPMs) در تولید تصاویر موفق بوده‌اند و در بسیاری از موارد از شبکه‌های مولد تقابلی (GANs) پیشی گرفته‌اند. بهبودها در DDPMها عمدتاً توسط تکنیک‌های نمونه‌گیری بهبود یافته، هدایت بدون استفاده از طبقه‌بند، بازفرمول‌بندی مدل‌های انتشار برای پیش‌بینی نویز به جای پیکسل‌ها و استفاده از پایپ‌لاین‌های DDPM آبشاری با مدل‌های انتشار پایه با وضوح پایین و نمونه‌بردارهای افزایش‌دهنده انجام شده است. در تمام مدل‌های انتشار ذکر شده، U-Netهای کانولوشنی به عنوان معماری ستون فقرات به کار رفته‌اند. کار همزمان نیز یک معماری جدید و کارآمد مبتنی بر توجه برای DDPMها معرفی کرده است. در این مقاله، ما به بررسی ترنسفورمرهای خالص می‌پردازیم.

هنگام ارزیابی پیچیدگی معماری در ادبیات تولید تصویر، استفاده از تعداد پارامترها یک عمل رایج است. با این حال، تعداد پارامترها می‌تواند نشانگر ضعیفی برای پیچیدگی مدل‌های تصویر باشد، زیرا به عنوان مثال، وضوح تصویر که به طور قابل توجهی بر عملکرد تأثیر می‌گذارد را در نظر نمی‌گیرد. در عوض، بسیاری از تحلیل‌های پیچیدگی مدل در این مقاله از منظر Gflops نظری است. این روش با ادبیات طراحی معماری که در آن Gflops به طور گسترده‌ای برای سنجش پیچیدگی استفاده می‌شود، هم‌خوانی دارد. در عمل، معیار طلایی پیچیدگی هنوز مورد بحث است زیرا اغلب به سناریوهای کاربردی خاص بستگی دارد. کارهای اصلی Nichol و Dhariwal در بهبود مدل‌های انتشار بیشتر به ما مرتبط است، جایی که آن‌ها مقیاس‌پذیری و ویژگی‌های Gflop معماری U-Net را تحلیل کرده‌اند. در این مقاله، ما بر کلاس ترنسفورمرها تمرکز می‌کنیم.

مدل‌های انتشار به عنوان مدل‌های مولد عمیق قدرتمند اخیراً برای تولید تصاویر با کیفیت بالا معرفی شده‌اند. آن‌ها به سرعت رشد کرده و در تولید متن به تصویر، تصویر به تصویر، تولید ویدئو، سنتز گفتار و سنتز سه‌بعدی کاربرد یافته‌اند. به همراه توسعه الگوریتم‌ها، انقلاب ستون فقرات نقش مرکزی در مدل‌های انتشار دارد. مثالی برجسته U-Net مبتنی بر شبکه عصبی کانولوشنی (CNN) است که در کارهای پیشین استفاده شده است. U-Net مبتنی بر CNN با گروهی از بلوک‌های نمونه‌برداری پایین، گروهی از بلوک‌های نمونه‌برداری بالا و اتصالات بلند بین دو گروه مشخص می‌شود که در مدل‌های انتشار برای وظایف تولید تصویر غالب است. از سوی دیگر، ویژن ترنسفورمرها (ViT) در وظایف مختلف بینایی نویدبخش بوده‌اند، جایی که ViT در مقایسه با رویکردهای مبتنی بر CNN قابل مقایسه یا حتی برتر بوده‌اند. بنابراین، یک سؤال طبیعی مطرح می‌شود: آیا وابستگی به U-Net مبتنی بر CNN در مدل‌های انتشار ضروری است؟

در این مقاله، ما یک معماری ساده و عمومی مبتنی بر ViT به نام U-ViT طراحی کرده‌ایم. U-ViT تمام ورودی‌ها از جمله زمان، شرط و پچ‌های تصویر نویزی را به عنوان توکن‌ها در نظر می‌گیرد. به‌طور حیاتی، U-ViT اتصالات بلند بین لایه‌های سطحی و عمیق را الهام گرفته از U-Net به کار می‌گیرد. به‌طور شهودی، ویژگی‌های سطح پایین برای هدف پیش‌بینی در سطح پیکسل در مدل‌های انتشار مهم هستند و این اتصالات می‌توانند آموزش شبکه پیش‌بینی مربوطه را آسان‌تر کنند. علاوه بر این، U-ViT به‌طور انتخابی یک بلوک کانولوشن 3×3 اضافی قبل از خروجی برای کیفیت بصری بهتر اضافه می‌کند.

ما U-ViT را در سه وظیفه محبوب ارزیابی می‌کنیم: تولید تصویر بدون شرط، تولید تصویر شرطی بر اساس کلاس و تولید متن به تصویر. در همه تنظیمات، U-ViT قابل مقایسه با U-Net مبتنی بر CNN با اندازه مشابه است و در برخی موارد برتر نیز می‌باشد. به ویژه، مدل‌های انتشار نهان با U-ViT به نمرات FID رکوردشکن 2.29 در تولید تصویر شرطی بر اساس کلاس در ImageNet 256×256 و 5.48 در تولید متن به تصویر در MS-COCO دست یافته‌اند. نتایج ما نشان می‌دهد که اتصالات بلند مهم هستند در حالی که عملگرهای نمونه‌برداری پایین/بالا در U-Net مبتنی بر CNN همیشه برای مدل‌های انتشار تصویر ضروری نیستند. ما باور داریم که U-ViT می‌تواند برای تحقیقات آینده در مورد ستون فقرات مدل‌های انتشار بینشی ارائه دهد و به مدل‌سازی مولد در مجموعه‌های داده‌های بزرگ و چندوجهی کمک کند.








































%\قسمت{ایده اصلی مقاله}
%ایده اصلی این مقاله نیز، حول محور مسئله مسیریابی در طراحی‌ها با استفاده از تکنیک‌های هوش مصنوعی قرار دارد با این تفاوت که در این مقاله مسیر‌یابی ها مختص FPGA است و الگوریتم پیشنهاد شده برای مسیریابی بهتر درون FPGA پیشنهاد شده است. الگوریتم ارائه شده در این مقاله نیز متن‌باز است و مبتنی بر \texttt{Python} و کتابخانه \texttt{PyTorch} است و از موازی سازی در سطح GPU پشتیبانی می‌کند. در این مقاله ادعا شده است که طول مسیرها تا ۰٫۴ تا ۱۲٫۷ \% کوتاه شده و سرعت مسیریابی نیز بیشتر از ۲ برابر روش‌های معمولی شده است.
%
%
%
%
%
%
%\قسمت{کار‌های پیشین}
%همانند مقاله قبل در این مقاله نیز اشاره شده است که روش‌های قدیمی که به روش‌های CAD\پاورقی{Computer-Aided Design} معروف هستند در گذشته به طور عمده مورد استفاده قرار میگرفته است و مرحله مسیریابی به تنهایی ۴۱ تا ۸۶ درصد از کل زمان‌بندی مسیر طراحی CAD را به خود اختصاص می‌دهد \مرجع{article9} و از این رو کاری بسیار زمان‌بر است. بنابر این کیفیت و کارایی الگوریتم های PAR\پاورقی{Placement and Routing} بر طراحی بهینه بسیار تاثیر گذار هستند.
%
%
%الگوریتم های بسیار زیادی مطرح شده است که همگی آنها مبتنی بر ابزار CAD ارائه شده توسط شرکت‌های سازنده FPGA هستند.
%
%برای اینکه شرکت های تولید کننده FPGA از تولید مجدد ابزار CAD به خصوص، برای یک FPGA خاص جلوگیری کنند، ابزاری متن باز مبتنی بر کتابخانه یادگیری عمیق \texttt{PyTorch} ارائه شده است.
%
%ایده های اصلی این مقاله را می‌توان به صورت زیر دسته بندی کرد:
%
%
%\شروع{فقرات}
%\فقره ابزار ارائه شده به نام \texttt{OpenPARF} است که ابزاری متن باز برای مسیریابی FPGA های پیشرفته، مبتنی بر یادگیری عمیق و قابل اجرا بر روی دو پلتفرم CPU و GPU است.
%\فقره این ابزار الگوریتم های مسیریابی غیر خطی را بر اساس یک میدان الکترواستاتیکی نا متقارن پیاده سازی می‌کند که قادر است به نتایج مکانیابی برتر تحت محدودیت های مختلف مسیریابی دست پیدا کند.
%\پایان{فقرات}
%
%
%
%
%\قسمت{مراحل انجام الگوریتم}
%مراحل انجام این الگوریتم در «شکل \رجوع{شکل:مراحل انجام الگوریتم OpenPARF}» نشان داده شده است. همانطور مشخص است، این الگوریتم دارای ۲ مرحله چینش و مسیریابی است.
%
%
%
%\شروع{شکل}[ht]
%\centerimg{img8.png}{12cm}
%\شرح{مراحل انجام الگوریتم OpenPARF}
%\برچسب{شکل:مراحل انجام الگوریتم OpenPARF}
%\پایان{شکل}
%
%
%
%در ابتدا فایل‌های اطلاعت مکان‌ها «فایل هایی با فرمت bookshelf» و فایل های ساختار و معماری مسیر‌یابی مورد نظر «فایل هایی با فرمت XML» در ساختار داده داخلی OpenPARF ساخته می‌شود و در مرحله دوم، بر اساس ساختار داده داخلی، OpenPARF از الگوریتم های مکان‌یابی مبتنی بر میدان‌های الکترو‌استاتیکی چندگانه مسئله مسیر‌یابی را در یک چارچوب بهینه‌سازی استاندارد استفاده می‌کند.
%
%پس از انجام مسیریابی در مرحله اول، الگوریتم تلاش می‌کند با انجام مسیریابی های دقیق تر و با جزئیات بیشتر، مشکلات موجود در مسیر یابی اولیه انجام شده را بر طرف نماید.
%
%پس این الگوریتم مسیر یابی از دو مرحله تشکیل می‌شود:
%
%\شروع{فقرات}
%\فقره مسیریابی اصلی سطح دانه درشت
%\فقره مسیر یابی دقیق و جزئی سطح دانه ریز
%\پایان{فقرات}
%
%در مرحله اول یک مسیر اصلی و کلی پیشنهاد می‌شود و در مرحله دوم، مسیر یابی به صورت دقیق و منطقه به منطقه بررسی می‌شود و بهترین خروجی را تولید می‌کند.
%
%
%
%
%
%\قسمت{مزایا و معایب}
%
%از مزایای روش پیشنهاد شده می‌توان به موارد زیر اشاره کرد:
%\شروع{فقرات}
%\فقره این مقاله نیز همانند قبلی یکی از مزیت های آن متن باز بودن آن است
%\فقره توسعه الگوریتم به دو زبان \texttt{Python} و \texttt{C++} 
%\فقره توسعه الگوریتم بر دو بستر CPU و GPU
%\فقره ارائه نتایج برای دو بنچ‌مارک صنعتی و اکادمیک جدید
%\فقره مقایسه بسیار گسترده LUT ها و FF ها و سایر منابع مصرفی FPGA به هنگام استفاده از این الگوریتم.
%\فقره و ...
%\پایان{فقرات}
%
%در کنار بیان مزایا می‌بایست به معایب پروژه را هم بیان کرد. در ادامه چند مورد از معایب پروژه انجام شده را بیان می‌کنیم:
%
%\شروع{فقرات}
%\فقره عدم اشاره مستقیم مقاله به ساختار شبکه‌عصبی استفاده شده در این الگوریتم
%\فقره نیازمند بودن به سیستمی قوی برای اجرای این الگوریتم. چرا که این الگوریتم بر روی سیستمی بسیار قوی آموزش داده شده است و به این نکته اشاره نشده است که مینیمم امکانات سیستم مورد نظر چه باید باشد که بتوان این الگوریتم را بر روی آن اجرا کرد.
%\فقره نیازمند بودن الگوریتم به FPGA های پیشرفته با منابع داخلی بالا. چرا که به نظر بنده این الگوریتم بر روی FPGA های قدیمی با منابع داخلی محدود قابل اجرا نمی‌باشد
%\فقره عدم صحبت از توان مصرفی الگوریتم
%\فقره عدم ارائه گزارش از خطا‌های ناشی از اجرای الگوریتم
%\فقره و ...
%\پایان{فقرات}
%
%
%
%
%
%
%\قسمت{اجرای عملی الگوریتم}
%
%\زیرقسمت{دانلود مخزن الگوریتم}
%
%با استفاده از دستور زیر، مخزن\پاورقی{Repository} الگوریتم را دانلود می‌کنیم.
%\begin{latin}
%	\texttt{\textcolor{blue}{\$} git clone https://github.com/PKU-IDEA/OpenPARF.git}
%\end{latin}
%
%
%\زیرقسمت{نصب وابستگی‌ها پیشنیاز‌ها}
%وابسگی‌های\پاورقی{Dependencies} مورد نیاز را به صورت زیر نصب می‌کنیم:
%\begin{latin}
%	\texttt{\# * create and activate conda environment}\\
%	\texttt{\textcolor{blue}{\$} mamba create --name openparf python=3.7}\\
%	\texttt{\textcolor{blue}{\$} mamba activate openparf}\\
%	\texttt{\# * common packages}\\
%	\texttt{\textcolor{blue}{\$} mamba install cmake boost bison}\\
%	\texttt{\# * Pytorch 1.7.1. Other version may also work, but have not been tested.}\\
%	\texttt{\textcolor{blue}{\$} mamba install pytorch==1.7.1 torchvision==0.8.2 cudatoolkit=11.0 -c pytorch}\\
%	\texttt{\# * python packages}\\
%	\texttt{\textcolor{blue}{\$} pip install hummingbird-ml pyyaml networkx tqdm}\\
%\end{latin}
%
%\قسمت{بیلد نرم‌افزار}
%به صورت زیر، OpenPARF را بیلد می‌کنیم:
%\begin{latin}
%	\texttt{\textcolor{blue}{\$} mkdir build}\\
%	\texttt{\textcolor{blue}{\$} cd build}\\
%	\texttt{\textcolor{blue}{\$} cmake ../OpenPARF -DCMAKE\_PREFIX\_PATH=\$CONDA\_PREFIX}\\
%	\texttt{-DPYTHON\_EXECUTABLE=\$(which python)-DPython3\_EXECUTABLE=\$(which python)}\\
%	\texttt{-DCMAKE\_INSTALL\_PREFIX=<installation directory>}\\
%	\texttt{\textcolor{blue}{\$} make -j8}\\
%	\texttt{\textcolor{blue}{\$} make install}\\
%\end{latin}
%
%\قسمت{دانلود بنچ‌مارک ها}
%بنچ‌مارک های مورد استفاده در این مقاله را می‌توان از آدرس‌های زیر دانلود نمود:
%
%\begin{latin}
%	\begin{enumerate}
%		\item ISPD 2016 FPGA Placement Benchmarks [\href{https://drive.google.com/file/d/1kzg0NfEmJvwzhJADPE_Q0UjS6UpVCMZZ/view}{download}]
%		\item ISPD 2016 FPGA Placement Flexshelf Benchmarks [\href{https://drive.google.com/file/d/1lwYSwfIPfzOxi_SfOZj5DyiwROLJDFd0/view}{download}]
%		\item ISPD 2017 FPGA Placement Benchmarks [\href{https://drive.google.com/file/d/1Uf9qIZ8WL_jk03sIlAoS9dIrvYH3d1pz/view}{download}]
%		\item ISPD 2017 FPGA Placement Flexshelf Benchmarks [\href{https://drive.google.com/file/d/1smt4lGUFdhs0TjPBzi9PqiyfA9n2Uwoy/view}{download}]
%	\end{enumerate}
%\end{latin}
%
%می توان به صورت زیر نیز بنچ‌مارک ها را در ترمینال دانلود کرد:
%\begin{latin}
%	\texttt{\textcolor{blue}{\$} curl <url> --output <output filename>}
%\end{latin}
%
%\قسمت{لینک کردن بنچ‌مارک ها}
%با استفاده از دستورات زیر، می‌توان بنچ‌مارک های دانلود شده را لینک کرد:
%\begin{latin}
%	\texttt{\textcolor{blue}{\$} ln -s <benchmark directory>/ispd2016 <installation}\\
%	\texttt{directory>/benchmarks/ispd2016}
%	
%	\texttt{\textcolor{blue}{\$} ln -s <benchmark directory>/ispd2016\_flexshelf <installation}\\
%	\texttt{directory>/benchmarks/ispd2016\_flexshelf}
%	
%	\texttt{\textcolor{blue}{\$} ln -s <benchmark directory>/ispd2017 <installation}\\
%	\texttt{directory>/benchmarks/ispd2017}
%	
%	\texttt{\textcolor{blue}{\$} ln -s <benchmark directory>/ispd2017\_flexshelf <installation}\\
%	\texttt{directory>/benchmarks/ispd2017\_flexshelf}
%\end{latin}
%
%
%\قسمت{اجرا کردن بنچ‌مارک ها}
%بنچ‌مارک ها را به صورت زیر می‌توان اجرا\پاورقی{Run} نمود:
%
%\begin{latin}
%	\texttt{\textcolor{blue}{\$} cd <installation directory>}\\
%	\texttt{\textcolor{blue}{\$} python openparf.py --config unittest/regression/ispd2016\_flexshelf/}\\
%	\texttt{FPGA01\_flexshelf.json}
%\end{latin}

\فصل{کارهای پیشین}\label{کارهای پیشین}
ترنسفورمرها به عنوان جایگزینی برای معماری‌های خاص حوزه‌ها در زمینه‌های مختلفی از جمله زبان، بینایی، یادگیری تقویتی و فراگیری متا معرفی شده‌اند. این مدل‌ها نشان داده‌اند که با افزایش اندازه مدل، توان محاسباتی و داده‌های آموزشی مقیاس‌پذیری قابل توجهی دارند. در خارج از حوزه زبان، ترنسفورمرها برای پیش‌بینی خودرگرسیو پیکسل‌ها و کدبوک‌های گسسته آموزش داده شده‌اند و در مدل‌های تولیدی ماسک شده نیز به کار رفته‌اند. همچنین در مدل‌های انتشار نویززدایی\پانویس{DDPM} برای تولید داده‌های غیرمکانی مانند تولید جاسازی‌های تصویر \lr{CLIP} در \lr{DALL·E 2} استفاده شده‌اند. در این مقاله \مرجع{peebles2023scalable}، خواص مقیاس‌پذیری ترنسفورمرها را هنگامی که به عنوان هسته مدل‌های انتشار تصویر استفاده می‌شوند، بررسی می‌کنیم.

مدل‌های انتشار نویززدایی احتمالاتی در تولید تصاویر موفق بوده‌اند و در بسیاری از موارد از شبکه‌های مولد تقابلی\پانویس{GANs} پیشی گرفته‌اند. بهبودها در \lr{DDPM}ها عمدتاً توسط تکنیک‌های نمونه‌گیری بهبود یافته، هدایت بدون استفاده از طبقه‌بند، بازفرمول‌بندی مدل‌های انتشار برای پیش‌بینی نویز به جای پیکسل‌ها و استفاده از پایپ‌لاین‌های \lr{DDPM} آبشاری با مدل‌های انتشار پایه با وضوح پایین و نمونه‌بردارهای افزایش‌دهنده انجام شده است. در تمام مدل‌های انتشار ذکر شده، \lr{U-Net}های کانولوشنی به عنوان معماری اصلی به کار رفته‌اند. کار همزمان نیز یک معماری جدید و کارآمد مبتنی بر توجه برای \lr{DDPM}ها معرفی کرده است. در این مقاله، ما به بررسی ترنسفورمرهای خالص می‌پردازیم. \مرجع{peebles2023scalable}

هنگام ارزیابی پیچیدگی معماری در ادبیات تولید تصویر، استفاده از تعداد پارامترها یک عمل رایج است. با این حال، تعداد پارامترها می‌تواند نشانگر ضعیفی برای پیچیدگی مدل‌های تصویر باشد، زیرا به عنوان مثال، وضوح تصویر که به طور قابل توجهی بر عملکرد تأثیر می‌گذارد را در نظر نمی‌گیرد. در عوض، بسیاری از تحلیل‌های پیچیدگی مدل در این مقاله از منظر \lr{Gflops} نظری است. این روش با ادبیات طراحی معماری که در آن \lr{Gflops} به طور گسترده‌ای برای سنجش پیچیدگی استفاده می‌شود، هم‌خوانی دارد. در عمل، معیار طلایی پیچیدگی هنوز مورد بحث است زیرا اغلب به سناریوهای کاربردی خاص بستگی دارد. کارهای اصلی \lr{Nichol} و \lr{Dhariwal} در بهبود مدل‌های انتشار بیشتر به ما مرتبط است، جایی که آن‌ها مقیاس‌پذیری و ویژگی‌های \lr{Gflop} معماری \lr{U-Net} را تحلیل کرده‌اند. در این مقاله، ما بر کلاس ترنسفورمرها تمرکز می‌کنیم. \مرجع{peebles2023scalable}

مدل‌های انتشار به عنوان مدل‌های مولد عمیق قدرتمند اخیراً برای تولید تصاویر با کیفیت بالا معرفی شده‌اند. آن‌ها به سرعت رشد کرده و در تولید متن به تصویر، تصویر به تصویر، تولید ویدئو، سنتز گفتار و سنتز سه‌بعدی کاربرد یافته‌اند. به همراه توسعه الگوریتم‌ها، انقلاب هسته نقش مرکزی در مدل‌های انتشار دارد. مثالی برجسته \lr{U-Net} مبتنی بر شبکه عصبی کانولوشنی است که در کارهای پیشین استفاده شده است. \lr{U-Net} مبتنی بر \lr{CNN} با گروهی از بلوک‌های نمونه‌برداری پایین، گروهی از بلوک‌های نمونه‌برداری بالا و اتصالات بلند بین دو گروه مشخص می‌شود که در مدل‌های انتشار برای وظایف تولید تصویر غالب است. از سوی دیگر، ویژن ترنسفورمرها در وظایف مختلف بینایی نویدبخش بوده‌اند، جایی که \lr{ViT} در مقایسه با رویکردهای مبتنی بر \lr{CNN} قابل مقایسه یا حتی برتر بوده‌اند. بنابراین، یک سوال طبیعی مطرح می‌شود: آیا وابستگی به \lr{U-Net} مبتنی بر \lr{CNN} در مدل‌های انتشار ضروری است؟

در این مقاله \مرجع{bao2023all}، ما یک معماری ساده و عمومی مبتنی بر \lr{ViT} به نام \lr{U-ViT} طراحی کرده‌ایم. \lr{U-ViT} تمام ورودی‌ها از جمله زمان، شرط و پچ‌های تصویر نویزی را به عنوان توکن‌ها در نظر می‌گیرد. به‌طور حیاتی، \lr{U-ViT} اتصالات بلند بین لایه‌های سطحی و عمیق را الهام گرفته از \lr{U-Net} به کار می‌گیرد. به‌طور شهودی، ویژگی‌های سطح پایین برای هدف پیش‌بینی در سطح پیکسل در مدل‌های انتشار مهم هستند و این اتصالات می‌توانند آموزش شبکه پیش‌بینی مربوطه را آسان‌تر کنند. علاوه بر این، \lr{U-ViT} به‌طور انتخابی یک بلوک کانولوشن 3×3 اضافی قبل از خروجی برای کیفیت بصری بهتر اضافه می‌کند.

ما \lr{U-ViT} را در دو کاربرد محبوب ارزیابی می‌کنیم:
\شروع{شمارش}
\فقره تولید تصویر بدون شرط
\فقره تولید تصویر شرطی بر اساس کلاس و تولید متن به تصویر
\فقره 

\پایان{شمارش}


در همه تنظیمات، \lr{U-ViT} قابل مقایسه با \lr{U-Net} مبتنی بر \lr{CNN} با اندازه مشابه است و در برخی موارد برتر نیز می‌باشد. به ویژه، مدل‌های انتشار نهان با \lr{U-ViT} به نمرات \lr{FID} رکوردشکن \lr{2.29} در تولید تصویر شرطی بر اساس کلاس در \lr{ImageNet 256×256} و \lr{5.48} در تولید متن به تصویر در \lr{MS-COCO} دست یافته‌اند. نتایج ما نشان می‌دهد که اتصالات بلند مهم هستند در حالی که عملگرهای نمونه‌برداری پایین/بالا در \lr{U-Net} مبتنی بر \lr{CNN} همیشه برای مدل‌های انتشار تصویر ضروری نیستند. ما باور داریم که \lr{U-ViT} می‌تواند برای تحقیقات آینده در مورد هسته مدل‌های انتشار بینشی ارائه دهد و به مدل‌سازی مولد در مجموعه‌های داده‌های بزرگ و چندوجهی کمک کند.